
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Linear Modeling</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/tabs.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://shawnrhoads.github.io/gu-psyc-347/module-02-00_Linear-Modeling.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Nonlinear Modeling" href="module-02-01_Nonlinear-Modeling.html" />
    <link rel="prev" title="Python Exercises" href="module-01-03_Python-Exercises.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KG3N20S55G"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-KG3N20S55G');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Module 00
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-00_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-01_Course-Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-02_Course-Assignments.html">
   Course Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-03_Reading-List.html">
   Reading List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-04_Getting-Started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-05_Final-Projects.html">
   Final Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-06_Contributing.html">
   Contributing
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 01
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-00_Jupyter-Notebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-01_Intro-to-Python.html">
   Intro to Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-02_Working-with-Data.html">
   Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-03_Python-Exercises.html">
   Python Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 02
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Linear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-01_Nonlinear-Modeling.html">
   Nonlinear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-02_Modeling-Exercises.html">
   Modeling Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 03
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-00_Two-Armed-Bandit.html">
   Two-Armed Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-01_Models-of-Learning.html">
   Models of Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-02_RL-Exercises.html">
   RL Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 04
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-00_Social-Learning.html">
   Social Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-01_Prosocial-RL-Exercises.html">
   Prosocial RL Exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-XX_Future-Directions.html">
   Future Directions
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <b>If you use these materials for teaching or research, please use the following citation:</b> Rhoads, S. A. & Gan, L. (2022). Computational models of human social behavior and neuroscience - An open educational course and Jupyter Book to advance computational training. <i>Journal of Open Source Education</i>, 5(47), 146. [<a href="https://doi.org/10.21105/jose.00146">10.21105/jose.00146</a>]<br><br><br>Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/module-02-00_Linear-Modeling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/shawnrhoads/gu-psyc-347"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/shawnrhoads/gu-psyc-347/issues/new?title=Issue%20on%20page%20%2Fmodule-02-00_Linear-Modeling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-of-this-tutorial">
   Goals of this tutorial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-linear-model">
   What is a linear model?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-simulations">
   Model Simulations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-fitting">
   Model Fitting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computing-mse">
     Computing MSE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-parameters">
     Model parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#least-squares-minimization">
     Least-squares minimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scipy-optimize-minimize">
     scipy.optimize.minimize
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analytic-solution-for-least-squares-optimization-bonus">
     Analytic solution for Least Squares Optimization (Bonus)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#actual-data-versus-fitted-data">
     Actual data versus fitted data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparison-to-a-statistics-package">
     Comparison to a statistics package
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multivariate-data">
     Multivariate data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix-least-squares-derivation">
   Appendix: Least-squares derivation
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Linear Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-of-this-tutorial">
   Goals of this tutorial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-linear-model">
   What is a linear model?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-simulations">
   Model Simulations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-fitting">
   Model Fitting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computing-mse">
     Computing MSE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-parameters">
     Model parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#least-squares-minimization">
     Least-squares minimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scipy-optimize-minimize">
     scipy.optimize.minimize
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analytic-solution-for-least-squares-optimization-bonus">
     Analytic solution for Least Squares Optimization (Bonus)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#actual-data-versus-fitted-data">
     Actual data versus fitted data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparison-to-a-statistics-package">
     Comparison to a statistics package
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multivariate-data">
     Multivariate data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix-least-squares-derivation">
   Appendix: Least-squares derivation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you are using Anconda, please re-download this file to current directory:</span>
<span class="c1"># https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/course-env.yml</span>
<span class="c1"># Then, run this cell</span>
<span class="c1"># !conda env update --file course-env.yml</span>
</pre></div>
</div>
</div>
</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-02-00_Linear-Modeling.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="linear-modeling">
<h1>Linear Modeling<a class="headerlink" href="#linear-modeling" title="Permalink to this headline">¶</a></h1>
<p>This tutorial was inspired by and adapted from the <a class="reference external" href="https://github.com/NeuromatchAcademy/course-content">Neuromatch Academy tutorials</a> [<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>].</p>
<div class="section" id="goals-of-this-tutorial">
<h2>Goals of this tutorial<a class="headerlink" href="#goals-of-this-tutorial" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="#what-is-a-linear-model">Specify a simple linear model</a></p></li>
<li><p><a class="reference external" href="#model-simulations">Simulate a linear model</a></p></li>
<li><p><a class="reference external" href="#model-fitting">Gain an understanding about parameters (e.g., intercept, slope) in a linear model</a></p></li>
</ol>
</div>
<div class="section" id="what-is-a-linear-model">
<h2>What is a linear model?<a class="headerlink" href="#what-is-a-linear-model" title="Permalink to this headline">¶</a></h2>
<p>In its most basic form, a linear model can be written like this (e.g., a simple linear regression):</p>
<div class="math notranslate nohighlight">
\[
y_n = intercept + b*x_n + \epsilon_n
\]</div>
<p>where <span class="math notranslate nohighlight">\(y\)</span> is the <strong>dependent (outcome) variable</strong> and <span class="math notranslate nohighlight">\(x\)</span> is an <strong>independent (explanatory/manipulated) variable</strong>—these variables represent data (each participant <span class="math notranslate nohighlight">\(n\)</span> has an observation at <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>).</p>
<p><span class="math notranslate nohighlight">\(y\)</span> is a function of <span class="math notranslate nohighlight">\(x\)</span> and is determined by 2 components:</p>
<ul class="simple">
<li><p>a non-random component: <span class="math notranslate nohighlight">\(intercept + \beta*x_n\)</span></p></li>
<li><p>random component: <span class="math notranslate nohighlight">\(\epsilon_n\)</span></p></li>
</ul>
<p>The <span class="math notranslate nohighlight">\(intercept\)</span> is the value of <span class="math notranslate nohighlight">\(y\)</span> when <span class="math notranslate nohighlight">\(x=0\)</span>. <span class="math notranslate nohighlight">\(\beta\)</span> is a weighted parameter that determines the slope of the fitted linear model. We will determine the values of these parameters by fitting a linear model.</p>
<p>The <span class="math notranslate nohighlight">\(error\)</span> (<span class="math notranslate nohighlight">\(\epsilon_n\)</span>) describes the random component of the linear relationship between <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>—this is the difference between the true values (<span class="math notranslate nohighlight">\(y\)</span>) and the predicted values (<span class="math notranslate nohighlight">\(\hat{y}\)</span>). We can solve this equation for the error:</p>
<div class="math notranslate nohighlight">
\[
y_n = (intercept + \beta*x_n) + \epsilon_n
\]</div>
<div class="math notranslate nohighlight">
\[
y_n = \hat{y_n} + \epsilon_n
\]</div>
<div class="math notranslate nohighlight">
\[
\epsilon_n = y_n - \hat{y_n}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s begin by importing packages</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">truncnorm</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Rectangle</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-simulations">
<h2>Model Simulations<a class="headerlink" href="#model-simulations" title="Permalink to this headline">¶</a></h2>
<p>Simulations are great ways to test models. By creating a simple synthetic dataset, we will know the true underlying model which allows us to see how our estimation efforts compare in uncovering the real model.</p>
<p>Below, we will simulate a linear relationship between two variables <code class="docutils literal notranslate"><span class="pre">x</span></code> (antisocial behavior) and <code class="docutils literal notranslate"><span class="pre">y</span></code> (distance kept from others during the COVID-19 pandemic), and then we will add some “noise” to those data. This will help us gain a better understanding about expected results from <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0244974">O’Connell, et al., (2021)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting a fixed seed to our random number generator </span>
<span class="c1"># ensures we will always</span>
<span class="c1"># get the same psuedorandom number sequence</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="c1"># Let&#39;s set some parameters</span>
<span class="n">beta</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.75</span>
<span class="n">n_subjects</span> <span class="o">=</span> <span class="mi">131</span>

<span class="c1"># Draw x</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="mi">347</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_subjects</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">139</span> <span class="c1"># range of STAB scores </span>
<span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mf">54.9</span><span class="p">,</span> <span class="mf">30.1</span> <span class="c1"># mean, and standard deviation</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">truncnorm</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="n">lower</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="n">sigma</span><span class="p">,</span>
                   <span class="p">(</span><span class="n">upper</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="n">sigma</span><span class="p">,</span>
                   <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span>
                   <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span>
                   <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_subjects</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">))</span>

<span class="c1"># sample from a standard normal distribution</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">n_subjects</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 

<span class="c1"># calculate y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">noise</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot a histogram</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Antisocial behavior&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_7_0.png" src="_images/module-02-00_Linear-Modeling_7_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot a histogram</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Distance from others&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_8_0.png" src="_images/module-02-00_Linear-Modeling_8_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the results</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># produces a scatter plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Antisocial behavior&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Distance from others&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_9_0.png" src="_images/module-02-00_Linear-Modeling_9_0.png" />
</div>
</div>
<p>Now that we have our noisy dataset, we can try to estimate the underlying model that produced it. We use MSE to evaluate how successful a particular slope estimate <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> is for explaining the data, with the closer to 0 the MSE is, the better our estimate fits the data.</p>
<hr></div>
<div class="section" id="model-fitting">
<h2>Model Fitting<a class="headerlink" href="#model-fitting" title="Permalink to this headline">¶</a></h2>
<p>Now, we will fit our simulated data to a simple linear regression, using least-squares optimization.</p>
<p><strong>Ordinary least squares</strong> is a very common optimization procedure that we are going to use for data fitting.</p>
<p>Let’s recall our simple linear model above. Suppose we have a set of measurements, <span class="math notranslate nohighlight">\(y_{n}\)</span> (the “dependent” variable) obtained for different input values, <span class="math notranslate nohighlight">\(x_{n}\)</span> (the “independent” or “explanatory” variable). Suppose we believe the measurements are proportional to the input values, but are corrupted by some (random) measurement errors, <span class="math notranslate nohighlight">\(\epsilon_{n}\)</span>, that is:</p>
<div class="math notranslate nohighlight">
\[\hat{y_{n}}= \beta_0 + \beta_1 x_{n}+\epsilon_{n}\]</div>
<p>for some unknown parameters (<span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>). The least squares regression problem uses <strong>mean squared error (MSE)</strong> as its objective function, it aims to find the values of <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> by minimizing the average of squared errors:</p>
<div class="math notranslate nohighlight">
\[
\min _{\beta} \frac{1}{N}\sum_{n=1}^{N}\left(y_{n}-\hat{y_{n}}\right)^{2}
\]</div>
<p>We will now explore how MSE is used in fitting a linear regression model to data.</p>
<div class="section" id="computing-mse">
<h3>Computing MSE<a class="headerlink" href="#computing-mse" title="Permalink to this headline">¶</a></h3>
<p>In this exercise we will implement a method to compute the mean squared error (MSE) for a set of inputs <span class="math notranslate nohighlight">\(x\)</span>, measurements <span class="math notranslate nohighlight">\(y\)</span>, and slope estimates <span class="math notranslate nohighlight">\(\hat{\beta_0}\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta_1}\)</span>. We will then compute and print the MSE for 3 different estimates of <span class="math notranslate nohighlight">\(\hat{\beta_1}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the mean squared error</span>

<span class="sd">    Args:</span>
<span class="sd">    beta_hats (list of floats): A list containing the estimate of the intercept parameter and the estimate of the slope parameter</span>
<span class="sd">    X (ndarray): An array of shape (samples,) that contains the input values.</span>
<span class="sd">    y (ndarray): An array of shape (samples,) that contains the corresponding measurement values to the inputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">    y_hat (float): The estimated y_hat computed from X and the estimated parameter(s).</span>
<span class="sd">    mse (float): The mean squared error of the model with the estimated parameter(s).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Compute the estimated y</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">+=</span> <span class="n">b</span><span class="o">*</span><span class="n">X</span><span class="p">[:,</span><span class="n">index</span><span class="p">]</span>
    
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Compute mean squared error</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">intercept</span> <span class="o">=</span> <span class="mi">347</span>
<span class="n">possible_betas</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.75</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.75</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.75</span><span class="p">]</span>

<span class="k">for</span> <span class="n">beta_hat</span> <span class="ow">in</span> <span class="n">possible_betas</span><span class="p">:</span>
        
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">MSE_val</span> <span class="o">=</span> <span class="n">mse</span><span class="p">([</span><span class="n">intercept</span><span class="p">,</span> <span class="n">beta_hat</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;beta_hat of </span><span class="si">{</span><span class="n">beta_hat</span><span class="si">}</span><span class="s2"> has an MSE of </span><span class="si">{</span><span class="n">MSE_val</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>beta_hat of -0.75 has an MSE of 4827.76
beta_hat of -1.75 has an MSE of 111.37
beta_hat of -2.75 has an MSE of 5438.72
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">beta_hat</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">possible_betas</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>

    <span class="c1"># True data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>

    <span class="c1"># Compute and plot predictions</span>
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">MSE_val</span> <span class="o">=</span> <span class="n">mse</span><span class="p">([</span><span class="n">intercept</span><span class="p">,</span> <span class="n">beta_hat</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">title</span><span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;$\hat</span><span class="se">{{</span><span class="s1">\beta</span><span class="se">}}</span><span class="s1">$= </span><span class="si">{</span><span class="n">beta_hat</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">MSE_val</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Anti-social behavior&#39;</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Distance from others&#39;</span><span class="p">)</span>
    
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_17_0.png" src="_images/module-02-00_Linear-Modeling_17_0.png" />
</div>
</div>
<hr></div>
<div class="section" id="model-parameters">
<h3>Model parameters<a class="headerlink" href="#model-parameters" title="Permalink to this headline">¶</a></h3>
<p>Using an interactive widget, we can easily see how changing intercept and slope estimates change a model fit. We display the <strong>residuals</strong> (differences between observed and predicted data) as line segments between the actual data and the corresponding predicted data on the model fit line.</p>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" integrity="sha512-5A8nwdMOWrSz20fDsjczgUidUBR8liPYU+WymTZP1lmY9G6Oc7HlZv156XqnsgNUzTyMefFTcsFH/tnJE/+xBg==" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/x-thebe-config">
     {
       requestKernel: true,
       binderOptions: {
         repo: "matplotlib/ipympl",
         ref: "0.6.1",
         repoProvider: "github",
       },
     }
</script>
<script src="https://unpkg.com/thebe@latest/lib/index.js"></script>
<button id="activateButton" style="width: 450px; height: 40px; font-size: 1.5em;">
     Click here to interact with this visualization
</button>
<script>
var bootstrapThebe = function() {
   thebelab.bootstrap();
}
document.querySelector("#activateButton").addEventListener('click', bootstrapThebe)
</script>
<pre data-executable="true" data-language="python">
# interactive display
import matplotlib.pyplot as plt
import ipywidgets as widgets
import numpy as np

# set up data
x0_viz = np.ones((131, 1))
x1_norm = np.random.normal(loc=54.9,scale=30.1,size=(131,1))
x1_viz = x1_norm - min(x1_norm)
X_viz = np.hstack((x0_viz, x1_viz))
noise_viz = np.random.normal(2, 10, (131,1)) 
y_viz = 347 - 1.75 * x1_viz + noise_viz

@widgets.interact(beta_hat=widgets.FloatSlider(-1.75, min=-3, max=0),
                  intercept=widgets.FloatSlider(347, min=100, max=400))
def plot_data_estimate(intercept, beta_hat):
    # compute error
    X, y = X_viz, y_viz
    y_hat = (intercept*X[:,0] + beta_hat*X[:,1]).reshape(len(y),1)
    MSE_val = np.mean((y - y_hat)**2)
    
    # plot
    fig, ax = plt.subplots()
    ax.scatter(X[:,1], y, label='Observed')  # our data scatter plot
    ax.plot(X[:,1], y_hat, color='r', label='Fit')  # our estimated model

    # plot residuals
    ymin = np.minimum(y, y_hat)
    ymax = np.maximum(y, y_hat)
    ax.vlines(X[:,1], ymin, ymax, 'g', alpha=0.5, label='Residuals')

    ax.set(
        title=fr"$intercept={intercept:0.2f}, \hat{{\beta}}$ = {beta_hat:0.2f}, MSE = {MSE_val:.2f}",
        xlabel='x',
        ylabel='y')
    
    ax.legend()
    plt.show()
</pre><div class="cell tag_hide-input tag_hide-output tag_skip-execution docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># interactive display (if not using Jupyter Book)</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">beta_hat</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="o">-</span><span class="mf">1.75</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                  <span class="n">intercept</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mi">347</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">400</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_data_estimate</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span> <span class="n">beta_hat</span><span class="p">):</span>
    <span class="c1"># compute error</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">intercept</span><span class="o">*</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_hat</span><span class="o">*</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">MSE_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># plot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>

    <span class="c1"># plot residuals</span>
    <span class="n">ymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">ymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Residuals&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">fr</span><span class="s2">&quot;$intercept=</span><span class="si">{</span><span class="n">intercept</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">, \hat</span><span class="se">{{</span><span class="s2">\beta</span><span class="se">}}</span><span class="s2">$ = </span><span class="si">{</span><span class="n">beta_hat</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">, MSE = </span><span class="si">{</span><span class="n">MSE_val</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<hr></div>
<div class="section" id="least-squares-minimization">
<h3>Least-squares minimization<a class="headerlink" href="#least-squares-minimization" title="Permalink to this headline">¶</a></h3>
<p>While the approach detailed above (computing MSE at various values of <span class="math notranslate nohighlight">\(\hat\beta\)</span>) quickly got us to a good estimate, it still relied on us guessing which beta values to select. If we didn’t pick good guesses to begin with, we might miss the best possible parameter values.</p>
<p>Thus, there must be a better way “guess-timate” them, right?</p>
<p>Why don’t we try an <strong>exhaustive search</strong> of across a specified range of parameter values?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exhaustive search </span>
<span class="n">param_b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">325</span><span class="p">,</span> <span class="mi">375</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">param_b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">.25</span><span class="p">)</span>

<span class="n">first_run</span> <span class="o">=</span> <span class="s1">&#39;first&#39;</span>
<span class="n">mse_out</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">b0</span> <span class="ow">in</span> <span class="n">param_b0</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">b1</span> <span class="ow">in</span> <span class="n">param_b1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">first_run</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">first_run</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">Params</span> <span class="o">=</span> <span class="p">[</span><span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">Params</span><span class="p">,</span> <span class="p">[</span><span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">]))</span>
        <span class="n">mse_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_out</span><span class="p">,</span> <span class="n">mse</span><span class="p">([</span><span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From out exhaustive search:</span>
<span class="c1"># let&#39;s see if we can recover the index with the smallest MSE</span>
<span class="n">min_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_out</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b0, b1 = </span><span class="si">{</span><span class="n">Params</span><span class="p">[</span><span class="n">min_index</span><span class="p">]</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">mse_out</span><span class="p">[</span><span class="n">min_index</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b0, b1 = [349.    -1.75], MSE = 105.48
</pre></div>
</div>
</div>
</div>
<p>We see that our fit is <span class="math notranslate nohighlight">\(b_0 = 349\)</span> and <span class="math notranslate nohighlight">\(b_1 = -1.75\)</span>, which is quite close to our original!</p>
<p><strong>We can also plot our search onto a heatmap!</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;b0&#39;</span><span class="p">:</span> <span class="n">Params</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="s1">&#39;b1&#39;</span><span class="p">:</span> <span class="n">Params</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> 
                                 <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mse_out</span><span class="p">})</span>
<span class="n">data_pivoted</span> <span class="o">=</span> <span class="n">grid_search_data</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s2">&quot;b0&quot;</span><span class="p">,</span> <span class="s2">&quot;b1&quot;</span><span class="p">,</span> <span class="s2">&quot;MSE&quot;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data_pivoted</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span>
            <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;mean squared error&#39;</span><span class="p">})</span>

<span class="c1"># add rectangle around minimum</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">Rectangle</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">24</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.25</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Grid Search</span><span class="se">\n</span><span class="s2">(minimized MSE value is darkest blue on grid)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_28_0.png" src="_images/module-02-00_Linear-Modeling_28_0.png" />
</div>
</div>
<hr></div>
<div class="section" id="scipy-optimize-minimize">
<h3>scipy.optimize.minimize<a class="headerlink" href="#scipy-optimize-minimize" title="Permalink to this headline">¶</a></h3>
<p>But, writing an exhaustive search by hand is prone to errors, too! It depends largely on the specified parameters for the search (i.e., we only sampled 300 to 450 in increments of .5 above for <span class="math notranslate nohighlight">\(b_0\)</span>).</p>
<p>It can also be very time-consuming and computationally-expensive.</p>
<p>Instead, we can utilize minimization algorithms that we optimized to solve minimization problems like this. Let’s use the <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> function, which takes in the following inputs:</p>
<ul class="simple">
<li><p>a cost function to minimize (<code class="docutils literal notranslate"><span class="pre">mse()</span></code> in our case)</p></li>
<li><p>starting points for the parameters to estimate (starting points for <code class="docutils literal notranslate"><span class="pre">b0</span></code> and <code class="docutils literal notranslate"><span class="pre">b1</span></code> in our case)</p></li>
<li><p>other arguments that need to be input into our objective function (<code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> in our case)</p></li>
</ul>
<p>It will return an <code class="docutils literal notranslate"><span class="pre">OptimizeResult</span></code> object containing the estimated parameters (along with the value of minimized MSE)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_to_minimize</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the mean squared error</span>

<span class="sd">    Args:</span>
<span class="sd">    beta_hats (list of floats): A list containing the estimate of the intercept parameter and the estimate of the slope parameter</span>
<span class="sd">    X (ndarray): An array of shape (samples,) that contains the input values.</span>
<span class="sd">    y (ndarray): An array of shape (samples,) that contains the corresponding measurement values to the inputs.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    mse (float): The mean squared error of the model with the estimated parameter(s).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Compute the estimated y</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">+=</span> <span class="n">b</span><span class="o">*</span><span class="n">X</span><span class="p">[:,</span><span class="n">index</span><span class="p">]</span>
    
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Compute mean squared error</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_observed_vs_predicted</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Plot observed vs predicted data</span>

<span class="sd">    Args:</span>
<span class="sd">    x (ndarray): observed x values</span>
<span class="sd">    y (ndarray): observed y values</span>
<span class="sd">    y_hat (ndarray): predicted y values</span>
<span class="sd">    beta_hats (ndarray): An array of shape (betas,) that contains the estimate of the slope parameter(s)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">MSE_val</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">beta_hats</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>

    <span class="c1"># plot residuals</span>
    <span class="n">ymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">ymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Residuals&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">fr</span><span class="s2">&quot;$intercept=</span><span class="si">{</span><span class="n">beta_hats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">, \hat</span><span class="se">{{</span><span class="s2">\beta</span><span class="se">}}</span><span class="s2">$ = </span><span class="si">{</span><span class="n">beta_hats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">, MSE = </span><span class="si">{</span><span class="n">MSE_val</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># minimize MSE using scipy.optimize.minimize</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_to_minimize</span><span class="p">,</span> <span class="c1"># objective function</span>
               <span class="p">(</span><span class="mi">350</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.75</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
               <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span> <span class="c1"># arguments</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b0, b1 = </span><span class="si">{</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">fun</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plot_observed_vs_predicted</span><span class="p">([</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b0, b1 = [352.01054797  -1.78736471], MSE = 104.68617090696347
</pre></div>
</div>
<img alt="_images/module-02-00_Linear-Modeling_33_1.png" src="_images/module-02-00_Linear-Modeling_33_1.png" />
</div>
</div>
<p>We see that we can get a better fit: <span class="math notranslate nohighlight">\(b_0 = 352.01\)</span> and <span class="math notranslate nohighlight">\(b_1 = -1.79\)</span>, which fairly accurate! Note that our <strong>MSE</strong> value is also smaller than last time!</p>
<hr></div>
<div class="section" id="analytic-solution-for-least-squares-optimization-bonus">
<h3>Analytic solution for Least Squares Optimization (Bonus)<a class="headerlink" href="#analytic-solution-for-least-squares-optimization-bonus" title="Permalink to this headline">¶</a></h3>
<p>While the approach detailed above (computing MSE at various values of <span class="math notranslate nohighlight">\(\hat\beta\)</span>) got us to a good estimate, we still had to rely on evaluating the MSE value across a grid of hand-specified values.</p>
<p>If we don’t pick a good range to begin with, or with enough granularity, we might miss the best possible parameters. Let’s go one step further, and instead of finding the minimum MSE from a set of candidate estimates, let’s solve for it analytically.</p>
<p>We can do this by minimizing a “cost function”. Mean squared error is a convex objective function, therefore we can compute its minimum using calculus (see appendix below for this derivation)! After computing the minimum, we find that:</p>
<div class="math notranslate nohighlight">
\[
\hat\beta = \frac{\vec{x}^\top \vec{y}}{\vec{x}^\top \vec{x}}
\]</div>
<p>This is known as solving the normal equation. For different ways of obtaining the solution, see the notes on <a class="reference external" href="https://www.cns.nyu.edu/~eero/NOTES/leastSquares.pdf">Least Squares Optimization</a> by Eero Simoncelli.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Ordinary least squares estimator for linear regression.</span>

<span class="sd">    Args:</span>
<span class="sd">    X (ndarray): design matrix of shape (n_samples, n_regressors)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>

<span class="sd">    Returns:</span>
<span class="sd">    ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Compute beta_hat using OLS</span>
    <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

    <span class="k">return</span> <span class="n">beta_hat</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute beta_hat</span>
<span class="n">beta_hat2</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b0=</span><span class="si">{</span><span class="n">beta_hat2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, b1=</span><span class="si">{</span><span class="n">beta_hat2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Compute MSE</span>
<span class="n">y_hat2</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b0=[352.0105366], b1=[-1.78736455]
MSE = 104.69
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="actual-data-versus-fitted-data">
<h3>Actual data versus fitted data<a class="headerlink" href="#actual-data-versus-fitted-data" title="Permalink to this headline">¶</a></h3>
<p>In addition to reviewing the residuals, we can also look at the actual simulated data (<code class="docutils literal notranslate"><span class="pre">y</span></code> or <span class="math notranslate nohighlight">\(y\)</span>) versus fitted data (<code class="docutils literal notranslate"><span class="pre">y_hat</span></code> or <span class="math notranslate nohighlight">\(\hat{y}\)</span>). In other words, we can visualize the how the fitted values (<span class="math notranslate nohighlight">\(\hat{y}\)</span>) compare to the actual data (<span class="math notranslate nohighlight">\(y\)</span>) to assess how well our model recovered our original parameters. We can also correlate <span class="math notranslate nohighlight">\(y\)</span> with <span class="math notranslate nohighlight">\(\hat{y}\)</span> (a good model fit will show a strong correlation). This is helpful because we are often dealing with more than one dimension.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># correlate y and y_hat</span>
<span class="n">corrcoef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">y_hat2</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Plot the results</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat2</span><span class="p">)</span>  <span class="c1"># produces a scatter plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;y (simulated data + noise)&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$\haty$ (fitted data)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">((</span><span class="sa">f</span><span class="s1">&#39;r=</span><span class="si">{</span><span class="n">corrcoef</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-00_Linear-Modeling_40_0.png" src="_images/module-02-00_Linear-Modeling_40_0.png" />
</div>
</div>
<p>Awesome! Looks pretty nice!</p>
<hr></div>
<div class="section" id="comparison-to-a-statistics-package">
<h3>Comparison to a statistics package<a class="headerlink" href="#comparison-to-a-statistics-package" title="Permalink to this headline">¶</a></h3>
<p>Okay, cool!</p>
<p>Let’s see how our manual linear model fitting compares to a typical statistical packages. Let’s import <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> and run a simple linear regression with our observed data!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="n">stat_res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>

<span class="n">y_hat_new</span> <span class="o">=</span> <span class="p">(</span><span class="n">stat_res</span><span class="o">.</span><span class="n">intercept</span> <span class="o">+</span> <span class="n">stat_res</span><span class="o">.</span><span class="n">slope</span><span class="o">*</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b1 = </span><span class="si">{</span><span class="n">stat_res</span><span class="o">.</span><span class="n">slope</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> , b0 = </span><span class="si">{</span><span class="n">stat_res</span><span class="o">.</span><span class="n">intercept</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat_new</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b1 = -1.79 , b0 = 352.01, MSE = 104.69
</pre></div>
</div>
</div>
</div>
<hr></div>
<div class="section" id="multivariate-data">
<h3>Multivariate data<a class="headerlink" href="#multivariate-data" title="Permalink to this headline">¶</a></h3>
<p>Now that we have considered the univariate case, we turn to the general linear model case, where we can have more than one regressor, or feature, in our input.</p>
<p>Recall that our original univariate linear model was given as</p>
<div class="math notranslate nohighlight">
\[
y = \beta x + \epsilon
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta\)</span> is the slope and <span class="math notranslate nohighlight">\(\epsilon\)</span> some noise. We can easily extend this to the multivariate scenario by adding another parameter for each additional feature</p>
<div class="math notranslate nohighlight">
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... +\beta_d x_d + \epsilon
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> is the intercept and <span class="math notranslate nohighlight">\(d\)</span> is the number of features (it is also the dimensionality of our input).</p>
<p>For now, we will focus on the two-dimensional case (<span class="math notranslate nohighlight">\(d=2\)</span>), which allows us to easily visualize our results.</p>
<p>In this case our model can be writen as:</p>
<div class="math notranslate nohighlight">
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s add age</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="n">b1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.84</span>
<span class="n">b2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">.68</span>

<span class="n">lower2</span><span class="p">,</span> <span class="n">upper2</span> <span class="o">=</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">65</span> <span class="c1"># range of ages</span>
<span class="n">mu2</span><span class="p">,</span> <span class="n">sigma2</span> <span class="o">=</span> <span class="mf">36.34</span><span class="p">,</span> <span class="mf">10.08</span> <span class="c1"># mean and standard deviation</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu2</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_subjects</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">X_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>

<span class="c1"># sample from a standard normal distribution</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">n_subjects</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 

<span class="n">y_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span><span class="o">*</span><span class="n">x1</span> <span class="o">+</span> <span class="n">b2</span><span class="o">*</span><span class="n">x2</span> <span class="o">+</span> <span class="n">noise</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_subjects</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute beta_hat</span>
<span class="n">beta_hat3</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X_a</span><span class="p">,</span> <span class="n">y_a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b0=</span><span class="si">{</span><span class="n">beta_hat3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, b1=</span><span class="si">{</span><span class="n">beta_hat3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, b2=</span><span class="si">{</span><span class="n">beta_hat3</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Compute MSE</span>
<span class="n">y_hat3</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_a</span> <span class="o">@</span> <span class="n">beta_hat3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_a</span> <span class="o">-</span> <span class="n">y_hat3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b0=[374.49097358], b1=[-1.81811949], b2=[-0.6804654]
MSE = 101.97
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>Ordinary least squares regression is an optimization procedure that can be used for fitting data to models (i.e., predicting a value for <span class="math notranslate nohighlight">\(y\)</span> given <span class="math notranslate nohighlight">\(x\)</span> by minimizing the MSE)</p>
<p><strong>Note</strong>: In this case, there is also an <em>analytical</em> solution to the minimization problem (see below). But as models become more complex, we will need to use a minimization algorithm to help us out!</p>
<hr></div>
</div>
<div class="section" id="appendix-least-squares-derivation">
<h2>Appendix: Least-squares derivation<a class="headerlink" href="#appendix-least-squares-derivation" title="Permalink to this headline">¶</a></h2>
<p>Here’s the derivation of the least squares solution.</p>
<p>First, set the derivative of the error with respect to <span class="math notranslate nohighlight">\(\beta\)</span> equal to zero (use chain rule),</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{\partial}{\partial\beta}\frac{1}{N}\sum_{i=1}^N(y_i - \beta x_i)^2 = 0 \\
\frac{1}{N}\sum_{i=1}^N-2x_i(y_i - \beta x_i) = 0
\end{split}\]</div>
<p>Now solving for <span class="math notranslate nohighlight">\(\beta\)</span>, we obtain an optimal value of:</p>
<div class="math notranslate nohighlight">
\[
\hat\beta = \frac{\sum_{i=1}^N x_i y_i}{\sum_{i=1}^N x_i^2}
\]</div>
<p>This can be written in vector notation as:</p>
<div class="math notranslate nohighlight">
\[
\hat\beta = \frac{\vec{x}^\top \vec{y}}{\vec{x}^\top \vec{x}}
\]</div>
<p>This is equivalent to the following code (used above):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
</pre></div>
</div>
<p>This is known as solving the <em>normal equations</em>. For different ways of obtaining the solution, see the notes on <a class="reference external" href="https://www.cns.nyu.edu/~eero/NOTES/leastSquares.pdf">Least Squares Optimization</a> by Eero Simoncelli.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="module-01-03_Python-Exercises.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Python Exercises</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="module-02-01_Nonlinear-Modeling.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Nonlinear Modeling</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Shawn A. Rhoads<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>