
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nonlinear Modeling</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/tabs.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://shawnrhoads.github.io/gu-psyc-347/module-02-01_Nonlinear-Modeling.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modeling Exercises" href="module-02-02_Modeling-Exercises.html" />
    <link rel="prev" title="Linear Modeling" href="module-02-00_Linear-Modeling.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KG3N20S55G"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-KG3N20S55G');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Module 00
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-00_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-01_Course-Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-02_Course-Assignments.html">
   Course Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-03_Reading-List.html">
   Reading List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-04_Getting-Started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-05_Final-Projects.html">
   Final Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-06_Contributing.html">
   Contributing
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 01
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-00_Jupyter-Notebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-01_Intro-to-Python.html">
   Intro to Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-02_Working-with-Data.html">
   Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-03_Python-Exercises.html">
   Python Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 02
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-00_Linear-Modeling.html">
   Linear Modeling
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Nonlinear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-02_Modeling-Exercises.html">
   Modeling Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 03
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-00_Two-Armed-Bandit.html">
   Two-Armed Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-01_Models-of-Learning.html">
   Models of Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-02_RL-Exercises.html">
   RL Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 04
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-00_Social-Learning.html">
   Social Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-01_Prosocial-RL-Exercises.html">
   Prosocial RL Exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-XX_Future-Directions.html">
   Future Directions
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/module-02-01_Nonlinear-Modeling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/shawnrhoads/gu-psyc-347"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/shawnrhoads/gu-psyc-347/issues/new?title=Issue%20on%20page%20%2Fmodule-02-01_Nonlinear-Modeling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-of-this-tutorial">
   Goals of this tutorial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-nonlinear-model">
   What is a nonlinear model?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-case-for-nonlinear-modeling-social-discounting">
   A case for nonlinear modeling: Social Discounting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-parameters">
     Model Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-comparison">
   Model comparison
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fitting-actual-data-to-models">
   Fitting actual data to models
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Nonlinear Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-of-this-tutorial">
   Goals of this tutorial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-nonlinear-model">
   What is a nonlinear model?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-case-for-nonlinear-modeling-social-discounting">
   A case for nonlinear modeling: Social Discounting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-parameters">
     Model Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-comparison">
   Model comparison
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fitting-actual-data-to-models">
   Fitting actual data to models
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-02-01_Nonlinear-Modeling.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="nonlinear-modeling">
<h1>Nonlinear Modeling<a class="headerlink" href="#nonlinear-modeling" title="Permalink to this headline">¶</a></h1>
<p>This tutorial was inspired by and adapted from the <a class="reference external" href="https://github.com/NeuromatchAcademy/course-content">Neuromatch Academy tutorials</a> [<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>], using a nonlinear hyperbolic model to assess social discounting.</p>
<div class="section" id="goals-of-this-tutorial">
<h2>Goals of this tutorial<a class="headerlink" href="#goals-of-this-tutorial" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="#what-is-a-nonlinear-model">Specifying a nonlinear model</a></p></li>
<li><p><a class="reference external" href="#a-case-for-nonlinear-modeling-social-discounting">Fitting data to a nonlinear model</a></p></li>
<li><p><a class="reference external" href="#model-comparison">Comparing models</a></p></li>
<li><p><a class="reference external" href="#fitting-actual-data-to-models">Working with actual data</a></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="what-is-a-nonlinear-model">
<h2>What is a nonlinear model?<a class="headerlink" href="#what-is-a-nonlinear-model" title="Permalink to this headline">¶</a></h2>
<p>Recall the general linear model, in which the multivariate relationship between a dependent variable (<span class="math notranslate nohighlight">\(y\)</span>) can be expressed as a linear combination of independent variables (<span class="math notranslate nohighlight">\(x_d\)</span>) that are multiplied by a weighted parameter or slope (<span class="math notranslate nohighlight">\(\beta_d\)</span>), plus some noise (<span class="math notranslate nohighlight">\(\epsilon\)</span>):</p>
<div class="math notranslate nohighlight">
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... +\beta_d x_d + \epsilon
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> is the intercept and <span class="math notranslate nohighlight">\(d\)</span> is the number of features (it is also the dimensionality of our input).</p>
<p>Nonlinear modeling simply implies that the relationship between <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(x_d\)</span> is more than a linear combination. Some common examples of nonlinear models include</p>
<p><strong>Sigmoid function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y=\frac{1}{1 + exp(\beta_0 + \beta_1x_1)}\)</span></p>
<p><strong>Exponential function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y = \beta_0*exp(-\beta_1x_1)\)</span></p>
<p><strong>Hyperbolic function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y=\frac{\beta_0}{1 + \beta_1x_1}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s plot some of these examples:</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="n">b0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">b1</span> <span class="o">=</span> <span class="mf">.04</span>
<span class="n">b2</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">b3</span> <span class="o">=</span> <span class="mf">.0125</span>
<span class="n">b4</span> <span class="o">=</span> <span class="mf">2.67</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Linear&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">b0</span> <span class="o">-</span> <span class="n">b1</span><span class="o">*</span><span class="n">x1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Sigmoid&#39;</span><span class="p">:</span> <span class="p">(</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b2</span> <span class="o">+</span> <span class="n">b4</span><span class="o">*</span><span class="n">x1</span><span class="p">))</span> <span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Exponential&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">80</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">b1</span><span class="o">*</span><span class="n">x1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Hyperbolic&#39;</span><span class="p">:</span> <span class="p">((</span><span class="mi">80</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">b3</span><span class="o">*</span><span class="n">x1</span><span class="p">)))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">values</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">axes</span><span class="p">):</span>
    
    <span class="c1"># True data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<hr></div>
<div class="section" id="a-case-for-nonlinear-modeling-social-discounting">
<h2>A case for nonlinear modeling: Social Discounting<a class="headerlink" href="#a-case-for-nonlinear-modeling-social-discounting" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a better understanding about some nonlinear models, let’s see how we can apply them to understand people’s prosocial preferences towards close others versus distant strangers. We will fit different models to understand the phenomenon known as <strong>social discounting</strong>, which describes how the amount of resources that individuals are willing to sacrifice for others (<span class="math notranslate nohighlight">\(v\)</span>) decreases as a hyperbolic function of social distance (<span class="math notranslate nohighlight">\(N\)</span>) <a class="reference external" href="https://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01699.x">(Jones &amp; Rachlin, 2006)</a>.</p>
<p>First, let’s simulate some data to get a better intuition about the parameters in the models (the intercept <span class="math notranslate nohighlight">\(v_0\)</span> and slope <span class="math notranslate nohighlight">\(k\)</span>):</p>
<div class="math notranslate nohighlight">
\[v=\frac{v_0}{1 + k*N}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="n">v0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>

<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">.03</span><span class="p">,</span> <span class="mf">.005</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>

<span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>

<span class="n">v</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">v</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">v0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">))</span> <span class="o">+</span> <span class="n">noise</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Social Discounting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amount Willing to Forgo (v)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Distance (N)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-parameters">
<h3>Model Parameters<a class="headerlink" href="#model-parameters" title="Permalink to this headline">¶</a></h3>
<p>We have two “free” parameters in our hyperbolic model: the intercept (<span class="math notranslate nohighlight">\(v0\)</span>) and slope (<span class="math notranslate nohighlight">\(k\)</span>). The intercept (<span class="math notranslate nohighlight">\(v0\)</span>) represents the value of “amount willing to forgo” (<span class="math notranslate nohighlight">\(v\)</span>) when social distance (<span class="math notranslate nohighlight">\(N\)</span>) equals <span class="math notranslate nohighlight">\(0\)</span>. In other words, this is how much an individual values outcomes for him/herself (the undiscounted value of the outcomes)—a larger <span class="math notranslate nohighlight">\(v0\)</span> would indicate that individuals value outcomes for themselves more (note that this parameter is somewhat difficult to interpret, so it is a common practice to add <span class="math notranslate nohighlight">\(+ 1\)</span> to social distance so that the intercept represents the amount willing to forgo for <span class="math notranslate nohighlight">\(N=1\)</span>). The slope (<span class="math notranslate nohighlight">\(k\)</span>) measures the degree of discounting—a smaller <span class="math notranslate nohighlight">\(k\)</span> describes more prosocial (or less selfish) choices for distant others while a larger <span class="math notranslate nohighlight">\(k\)</span> describes more selfish (or less prosocial) choices for distant others.</p>
<p>To start off, let’s create three functions in Python that compute <span class="math notranslate nohighlight">\(v\)</span> (amount willing to forgo) as a function of <span class="math notranslate nohighlight">\(N\)</span> (social distance).</p>
<p>In both the exponential and hyperbolic case, we want to estimate the intercepts (<span class="math notranslate nohighlight">\(v_0\)</span>) and discounting rates (<span class="math notranslate nohighlight">\(k\)</span>) for each participant. We can compute these by minimizing the mean squared error (just like last time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_linear</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>   
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_exponential</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="n">v0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_hyperbolic</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="p">(</span><span class="n">v0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">))</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize dictionary to store results</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lin&quot;</span><span class="p">:</span> <span class="p">[],</span>
           <span class="s2">&quot;exp&quot;</span><span class="p">:</span> <span class="p">[],</span>
           <span class="s2">&quot;hyp&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="c1"># minimize MSE for linear function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_linear</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="o">-</span><span class="mf">.3</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_exponential</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">92</span><span class="p">,</span> <span class="mf">.6</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Linear: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Exponential: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hyperbolic: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fits</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">axes</span><span class="p">):</span>

    <span class="c1"># True data</span>
    <span class="n">v_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_mean</span><span class="p">,</span> 
               <span class="n">alpha</span> <span class="o">=</span> <span class="mf">.75</span><span class="p">,</span>
               <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Observed (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">fits</span><span class="o">.</span><span class="n">x</span>
    <span class="n">mse_val</span> <span class="o">=</span> <span class="n">fits</span><span class="o">.</span><span class="n">fun</span>

    <span class="c1"># Compute and plot predictions</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;lin&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="n">N</span>
    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;hyp&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
        
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>
    
    <span class="c1"># plot residuals</span>
    <span class="n">vmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">v_mean</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">)</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">v_mean</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Residuals&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
      <span class="n">title</span><span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;$k$= </span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">mse_val</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
      <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;v&#39;</span><span class="p">)</span>
    
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Note that all of these model fits assume a <strong>fixed</strong> intercept (<span class="math notranslate nohighlight">\(v_o\)</span>) and <strong>fixed</strong> slope (<span class="math notranslate nohighlight">\(k\)</span>) across participants—in other words, these are the <strong>average values</strong> across the entire sample.</p>
<p>In reality, we know that intercepts and slopes vary across participants, and can plot the differences below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot all individual subjects</span>
<span class="k">for</span> <span class="n">v_subj</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_subj</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>

<span class="c1"># plot mean model fit</span>
<span class="n">v_hat</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>        
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> 
         <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Social Discounting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amount Willing to Forgo (v)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Distance (N)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See small differences between fitted and observed values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v_hat</span><span class="si">}</span><span class="s1"> -- Fits&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v_mean</span><span class="si">}</span><span class="s1"> -- Observed&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Thus, it might be better to make inferences with our data by allowing the intercepts and slopes to vary across participants. Fitting separate models for each participant is one way (of many) to accomplish this.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    
    <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                   <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                   <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                   <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                   <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">: v0 = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can plot the distributions of <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(k\)</span> across participants</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_df</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;v0&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_df</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<hr></div>
</div>
<div class="section" id="model-comparison">
<h2>Model comparison<a class="headerlink" href="#model-comparison" title="Permalink to this headline">¶</a></h2>
<p>Above, we can see that the hyperbolic model fits the data best, but typically the best fitting model isn’t so obvious. Thus, we can use methods such as <span class="math notranslate nohighlight">\(R^2\)</span> or the <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Bayesian Information Criterion</a> (<span class="math notranslate nohighlight">\(BIC\)</span>) to compare model fits. The model with the lowest <span class="math notranslate nohighlight">\(BIC\)</span> value is the best fitting model in a finite set of models.</p>
<p>The <span class="math notranslate nohighlight">\(BIC\)</span> penalizes free parameters (see constant term: <span class="math notranslate nohighlight">\(k*ln(n)\)</span>):</p>
<div class="math notranslate nohighlight">
\[ BIC = -2*ln(MSE) + p*ln(n)\]</div>
<p>Here, <span class="math notranslate nohighlight">\(n\)</span> is the total number of observations in your sample (e.g., sample size), <span class="math notranslate nohighlight">\(p\)</span> the number of parameters estimated by the model (we are estimating two parameters in our model: <span class="math notranslate nohighlight">\(v0\)</span> and <span class="math notranslate nohighlight">\(k\)</span>), and <span class="math notranslate nohighlight">\(MSE\)</span> is the mean sqauared error of the model. Remember that a lower <span class="math notranslate nohighlight">\(BIC\)</span> value is better; Adding the term <span class="math notranslate nohighlight">\(p*ln(n)\)</span> penalizes the model fit by the number of free parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_bic</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">mse</span><span class="p">,</span> <span class="n">num_params</span><span class="p">):</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_params</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bic</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the Bayesian Information Criterion (bic)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="n">calculate_bic</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v_mean</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> (BIC): </span><span class="si">{</span><span class="n">bic</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can now show that the hyperbolic model is the model with the lowest <span class="math notranslate nohighlight">\(BIC\)</span> value (out of the models tested above).</p>
<hr></div>
<div class="section" id="fitting-actual-data-to-models">
<h2>Fitting actual data to models<a class="headerlink" href="#fitting-actual-data-to-models" title="Permalink to this headline">¶</a></h2>
<p>Now that we’ve seen two examples of simulating data and model parameter recovery. Let’s try to fit actual data to these models.</p>
<p>We will use a subset of the data from <a class="reference external" href="https://www.nature.com/articles/s41562-017-0100">Vekaria et al. (2017)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First let&#39;s load in the data</span>

<span class="c1"># here, we are just going to download data from the web (no need to edit these lines, but try to figure out what they are doing)</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/Vekaria-et-al-2017_data.csv&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;subject&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that our data are formatted with participants as rows and amounts willing to forgo at each social distance as columns. To use our functions above, we will need to make sure our <span class="math notranslate nohighlight">\(v\)</span> data have shape <code class="docutils literal notranslate"><span class="pre">(n_subjects,</span> <span class="pre">7)</span></code>.</p>
<p>Let’s convert the pd.DataFrame to a np.array:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vekaria_data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vekaria_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>First, let’s fit all of the data together, with fixed intercepts and slopes, for both the hyperbolic model and the exponential model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fit1</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
               <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
               <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="c1"># arguments</span>
               <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
               <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for exponential function using scipy.optimize.minimize</span>
<span class="n">fit2</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_exponential</span><span class="p">,</span> <span class="c1"># objective function</span>
               <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
               <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="c1"># arguments</span>
               <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
               <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fig, axes = plt.subplots()</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>    

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed (mean)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Hyperbolic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fit2</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exponential&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Based on this plot, we can clearly see how much better the hyperbolic model is at explaining the variance in the data. We can confirm this again using the <span class="math notranslate nohighlight">\(BIC\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the Bayesian Information Criterion (bic)</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;hyperbolic&#39;</span><span class="p">,</span> <span class="s1">&#39;exponential&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">fit1</span><span class="p">,</span> <span class="n">fit2</span><span class="p">]):</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="n">calculate_bic</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vekaria_data</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> (BIC): </span><span class="si">{</span><span class="n">bic</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">res_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    
    <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                   <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                   <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                   <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                   <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">: v0 = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that some participants did not do very well with model fitting. For most, this is because their “amounts willing to forgo” do not vary across social distances.</p>
<p>To account for this, let’s check which subjects these are.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="n">subj_v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subj_v</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;no variation for subject #</span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">subj_v</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Three participants sacrificed all of their resources for all social others. Let’s assign <code class="docutils literal notranslate"><span class="pre">k=0</span></code> and <code class="docutils literal notranslate"><span class="pre">v0=85</span></code> to these participants since there is no variation in their preferences. This is eqivalent to a straight horizontal line (no discounting) at <span class="math notranslate nohighlight">\(v=85\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">hyp_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="n">subj_v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subj_v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">subj_v</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">595</span><span class="p">:</span>
            
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">80</span> <span class="c1"># </span>
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;assigning k=0 for subject #</span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">subj_v</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    
        <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                       <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                       <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                       <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                       <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>

<span class="n">res_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">hyp_vekaria</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_vekaria</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;v0&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_vekaria</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Yay! Now, we can use these data for subsequent analyses! Note the little variation in <span class="math notranslate nohighlight">\(v_0\)</span>. Also note that <span class="math notranslate nohighlight">\(k\)</span> is not parametric (e.g., not normally distributed), so we would need to conduct subsequent analyses using non-parametric approaches.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="module-02-00_Linear-Modeling.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Linear Modeling</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="module-02-02_Modeling-Exercises.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modeling Exercises</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Shawn A. Rhoads<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>