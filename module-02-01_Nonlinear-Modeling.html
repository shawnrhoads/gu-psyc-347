
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nonlinear Modeling</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e2363ea40746bee74734a24ffefccd78.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://shawnrhoads.github.io/gu-psyc-347/module-02-01_Nonlinear-Modeling.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modeling Exercises" href="module-02-02_Modeling-Exercises.html" />
    <link rel="prev" title="Linear Modeling" href="module-02-00_Linear-Modeling.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Module 00
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-00_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-01_Course-Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-02_Course-Assignments.html">
   Course Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-03_Reading-List.html">
   Reading List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-04_Getting-Started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-05_Final-Projects.html">
   Final Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-06_Contributing.html">
   Contributing
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 01
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-00_Jupyter-Notebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-01_Intro-to-Python.html">
   Intro to Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-02_Working-with-Data.html">
   Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-03_Python-Exercises.html">
   Python Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 02
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-00_Linear-Modeling.html">
   Linear Modeling
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Nonlinear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-02_Modeling-Exercises.html">
   Modeling Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 03
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-00_Two-Armed-Bandit.html">
   Two-Armed Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-01_Models-of-Learning.html">
   Models of Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-02_RL-Exercises.html">
   RL Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 04
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-00_Social-Learning.html">
   Social Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-04-01_Prosocial-RL-Exercises.html">
   Prosocial RL Exercises
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/module-02-01_Nonlinear-Modeling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/shawnrhoads/gu-psyc-347"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/shawnrhoads/gu-psyc-347/issues/new?title=Issue%20on%20page%20%2Fmodule-02-01_Nonlinear-Modeling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals-of-this-tutorial">
   Goals of this tutorial
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-nonlinear-model">
   What is a nonlinear model?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-case-for-nonlinear-modeling-social-discounting">
   A case for nonlinear modeling: Social Discounting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-parameters">
     Model Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-comparison">
   Model comparison
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fitting-actual-data-to-models">
   Fitting actual data to models
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-02-01_Nonlinear-Modeling.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="nonlinear-modeling">
<h1>Nonlinear Modeling<a class="headerlink" href="#nonlinear-modeling" title="Permalink to this headline">¶</a></h1>
<p>This tutorial was inspired by and adapted from the <a class="reference external" href="https://github.com/NeuromatchAcademy/course-content">Neuromatch Academy tutorials</a> [<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>], using a nonlinear hyperbolic model to assess social discounting.</p>
<div class="section" id="goals-of-this-tutorial">
<h2>Goals of this tutorial<a class="headerlink" href="#goals-of-this-tutorial" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="#what-is-a-nonlinear-model?">Specifying a nonlinear models</a></p></li>
<li><p><a class="reference external" href="#a-case-for-nonlinear-modeling:-social-discounting">Fitting data to a nonlinear model</a></p></li>
<li><p><a class="reference external" href="#model-comparison">Comparing models</a></p></li>
<li><p><a class="reference external" href="#fitting-actual-data-to-models">Working with actual data</a></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="what-is-a-nonlinear-model">
<h2>What is a nonlinear model?<a class="headerlink" href="#what-is-a-nonlinear-model" title="Permalink to this headline">¶</a></h2>
<p>Recall the general linear model, in which the multivariate relationship between a dependent variable (<span class="math notranslate nohighlight">\(y\)</span>) can be expressed as a linear combination of independent variables (<span class="math notranslate nohighlight">\(x_d\)</span>) that are multiplied by a weighted parameter or slope (<span class="math notranslate nohighlight">\(\beta_d\)</span>), plus some noise (<span class="math notranslate nohighlight">\(\epsilon\)</span>):</p>
<div class="math notranslate nohighlight">
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... +\beta_d x_d + \epsilon
\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> is the intercept and <span class="math notranslate nohighlight">\(d\)</span> is the number of features (it is also the dimensionality of our input).</p>
<p>Nonlinear modeling simply implies that the relationship between <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(x_d\)</span> is more than a linear combination. Some common examples of nonlinear models include</p>
<p><strong>Quadratic function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1x_1 + \beta_2x_1^2\)</span></p>
<p><strong>Sigmoid function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y=\frac{1}{1 + exp(\beta_0 + \beta_1x_1)}\)</span></p>
<p><strong>Exponential function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y = \beta_0*exp(-\beta_1x_1)\)</span></p>
<p><strong>Hyperbolic function</strong>:</p>
<p><span class="math notranslate nohighlight">\(y=\frac{\beta_0}{1 + \beta_1x_1}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s plot some of these examples:</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="n">b0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">b1</span> <span class="o">=</span> <span class="mf">.04</span>
<span class="n">b2</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">b3</span> <span class="o">=</span> <span class="mf">.0125</span>
<span class="n">b4</span> <span class="o">=</span> <span class="mf">2.67</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Linear&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">b0</span> <span class="o">-</span> <span class="n">b1</span><span class="o">*</span><span class="n">x1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Quadratic&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">b0</span> <span class="o">+</span> <span class="n">b1</span><span class="o">*</span><span class="n">x1</span> <span class="o">-</span> <span class="n">b2</span><span class="o">*</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Sigmoid&#39;</span><span class="p">:</span> <span class="p">(</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b2</span> <span class="o">+</span> <span class="n">b4</span><span class="o">*</span><span class="n">x1</span><span class="p">))</span> <span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Exponential&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">80</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">b1</span><span class="o">*</span><span class="n">x1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
     <span class="s1">&#39;Hyperbolic&#39;</span><span class="p">:</span> <span class="p">((</span><span class="mi">80</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">b3</span><span class="o">*</span><span class="n">x1</span><span class="p">)))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">values</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">axes</span><span class="p">):</span>
    
    <span class="c1"># True data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_5_0.png" src="_images/module-02-01_Nonlinear-Modeling_5_0.png" />
</div>
</div>
<hr></div>
<div class="section" id="a-case-for-nonlinear-modeling-social-discounting">
<h2>A case for nonlinear modeling: Social Discounting<a class="headerlink" href="#a-case-for-nonlinear-modeling-social-discounting" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a better understanding about some nonlinear models, let’s see how we can apply them to understand people’s prosocial preferences towards close others versus distant strangers. We will fit different models to understand the phenomenon known as <strong>social discounting</strong>, which describes how the amount of resources that individuals are willing to sacrifice for others (<span class="math notranslate nohighlight">\(v\)</span>) decreases as a hyperbolic function of social distance (<span class="math notranslate nohighlight">\(N\)</span>) <a class="reference external" href="https://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01699.x">(Jones &amp; Rachlin, 2006)</a>.</p>
<p>First, let’s simulate some data to get a better intuition about the parameters in the models (the intercept <span class="math notranslate nohighlight">\(v_0\)</span> and slope <span class="math notranslate nohighlight">\(k\)</span>):</p>
<div class="math notranslate nohighlight">
\[v=\frac{v_0}{1 + k*N}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

<span class="n">v0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>

<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">.03</span><span class="p">,</span> <span class="mf">.005</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>

<span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">])</span>

<span class="n">v</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">v</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">v0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">))</span> <span class="o">+</span> <span class="n">noise</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Social Discounting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amount Willing to Forgo (v)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Distance (N)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_8_0.png" src="_images/module-02-01_Nonlinear-Modeling_8_0.png" />
</div>
</div>
<div class="section" id="model-parameters">
<h3>Model Parameters<a class="headerlink" href="#model-parameters" title="Permalink to this headline">¶</a></h3>
<p>We have two “free” parameters in our hyperbolic model: the intercept (<span class="math notranslate nohighlight">\(v0\)</span>) and slope (<span class="math notranslate nohighlight">\(k\)</span>). The intercept (<span class="math notranslate nohighlight">\(v0\)</span>) represents the value of “amount willing to forgo” (<span class="math notranslate nohighlight">\(v\)</span>) when social distance (<span class="math notranslate nohighlight">\(N\)</span>) equals <span class="math notranslate nohighlight">\(0\)</span>. In other words, this is how much an individual values outcomes for him/herself (the undiscounted value of the outcomes)—a larger <span class="math notranslate nohighlight">\(v0\)</span> would indicate that individuals value outcomes for themselves more (note that this parameter is somewhat difficult to interpret, so it is a common practice to add <span class="math notranslate nohighlight">\(+ 1\)</span> to social distance so that the intercept represents the amount willing to forgo for <span class="math notranslate nohighlight">\(N=1\)</span>). The slope (<span class="math notranslate nohighlight">\(k\)</span>) measures the degree of discounting—a smaller <span class="math notranslate nohighlight">\(k\)</span> describes more prosocial (or less selfish) choices for distant others while a larger <span class="math notranslate nohighlight">\(k\)</span> describes more selfish (or less prosocial) choices for distant others.</p>
<p>To start off, let’s create three functions in Python that compute <span class="math notranslate nohighlight">\(v\)</span> (amount willing to forgo) as a function of <span class="math notranslate nohighlight">\(N\)</span> (social distance).</p>
<p>In both the exponential and hyperbolic case, we want to estimate the intercepts (<span class="math notranslate nohighlight">\(v_0\)</span>) and discounting rates (<span class="math notranslate nohighlight">\(k\)</span>) for each participant. We can compute these by minimizing the mean squared error (just like last time).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_linear</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>   
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_exponential</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="n">v0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mse_hyperbolic</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">v_fit</span> <span class="o">=</span> <span class="p">(</span><span class="n">v0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">))</span>
    
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_fit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize dictionary to store results</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lin&quot;</span><span class="p">:</span> <span class="p">[],</span>
           <span class="s2">&quot;exp&quot;</span><span class="p">:</span> <span class="p">[],</span>
           <span class="s2">&quot;hyp&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="c1"># minimize MSE for linear function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_linear</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="o">-</span><span class="mf">.3</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_exponential</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">92</span><span class="p">,</span> <span class="mf">.6</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                          <span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                          <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="c1"># arguments</span>
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                          <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Linear: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;lin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Exponential: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;exp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Hyperbolic: v0 = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear: v0 = 75.27, k = -0.609, MSE = 59.00
Exponential: v0 = 80.75, k = 0.016, MSE = 16.90
Hyperbolic: v0 = 85.20, k = 0.030, MSE = 4.86
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fits</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">axes</span><span class="p">):</span>

    <span class="c1"># True data</span>
    <span class="n">v_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_mean</span><span class="p">,</span> 
               <span class="n">alpha</span> <span class="o">=</span> <span class="mf">.75</span><span class="p">,</span>
               <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Observed (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our data scatter plot</span>
    
    <span class="n">v0</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">fits</span><span class="o">.</span><span class="n">x</span>
    <span class="n">mse_val</span> <span class="o">=</span> <span class="n">fits</span><span class="o">.</span><span class="n">fun</span>

    <span class="c1"># Compute and plot predictions</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;lin&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="n">N</span>
    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;exp&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;hyp&quot;</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
        
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>
    
    <span class="c1"># plot residuals</span>
    <span class="n">vmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">v_mean</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">)</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">v_mean</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Residuals&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
      <span class="n">title</span><span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;$k$= </span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">mse_val</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span>
      <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;v&#39;</span><span class="p">)</span>
    
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_15_0.png" src="_images/module-02-01_Nonlinear-Modeling_15_0.png" />
</div>
</div>
<p>Note that all of these model fits assume a <strong>fixed</strong> intercept (<span class="math notranslate nohighlight">\(v_o\)</span>) and <strong>fixed</strong> slope (<span class="math notranslate nohighlight">\(k\)</span>) across participants—in other words, these are the <strong>average values</strong> across the entire sample.</p>
<p>In reality, we know that intercepts and slopes vary across participants, and can plot the differences below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot all individual subjects</span>
<span class="k">for</span> <span class="n">v_subj</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_subj</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>

<span class="c1"># plot mean model fit</span>
<span class="n">v_hat</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;hyp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>        
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> 
         <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fit (mean)&#39;</span><span class="p">)</span>  <span class="c1"># our estimated model</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Social Discounting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amount Willing to Forgo (v)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Social Distance (N)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_17_0.png" src="_images/module-02-01_Nonlinear-Modeling_17_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See small differences between fitted and observed values</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v_hat</span><span class="si">}</span><span class="s1"> -- Fits&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v_mean</span><span class="si">}</span><span class="s1"> -- Observed&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[82.74082908 80.42375602 74.19083832 65.70397109 53.47069093 34.30767544
 21.47846286] -- Fits
[82.80278641 80.45272539 74.15481504 65.62721642 53.40723605 34.34937097
 21.58152985] -- Observed
</pre></div>
</div>
</div>
</div>
<p>Thus, it might be better to make inferences with our data by allowing the intercepts and slopes to vary across participants. Fitting separate models for each participant is one way (of many) to accomplish this.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    
    <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                   <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                   <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                   <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                   <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">: v0 = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 0: v0 = 87.34, k = 0.027, MSE = 0.01
subject 1: v0 = 86.74, k = 0.032, MSE = 0.00
subject 2: v0 = 85.18, k = 0.035, MSE = 0.04
subject 3: v0 = 83.00, k = 0.028, MSE = 0.00
subject 4: v0 = 86.56, k = 0.032, MSE = 0.01
subject 5: v0 = 84.06, k = 0.032, MSE = 0.01
subject 6: v0 = 86.89, k = 0.028, MSE = 0.00
subject 7: v0 = 86.93, k = 0.033, MSE = 0.01
subject 8: v0 = 85.61, k = 0.032, MSE = 0.01
subject 9: v0 = 85.08, k = 0.026, MSE = 0.01
subject 10: v0 = 84.65, k = 0.027, MSE = 0.01
subject 11: v0 = 83.70, k = 0.032, MSE = 0.00
subject 12: v0 = 85.19, k = 0.027, MSE = 0.01
subject 13: v0 = 83.93, k = 0.024, MSE = 0.03
subject 14: v0 = 82.90, k = 0.038, MSE = 0.14
subject 15: v0 = 87.24, k = 0.030, MSE = 0.00
subject 16: v0 = 82.73, k = 0.033, MSE = 0.01
subject 17: v0 = 83.61, k = 0.025, MSE = 0.02
subject 18: v0 = 82.53, k = 0.031, MSE = 0.00
subject 19: v0 = 85.92, k = 0.031, MSE = 0.00
subject 20: v0 = 83.91, k = 0.032, MSE = 0.00
subject 21: v0 = 91.07, k = 0.035, MSE = 0.04
subject 22: v0 = 88.52, k = 0.034, MSE = 0.03
subject 23: v0 = 85.38, k = 0.031, MSE = 0.00
subject 24: v0 = 85.26, k = 0.034, MSE = 0.02
subject 25: v0 = 85.56, k = 0.031, MSE = 0.00
subject 26: v0 = 88.74, k = 0.037, MSE = 0.09
subject 27: v0 = 86.92, k = 0.026, MSE = 0.01
subject 28: v0 = 83.56, k = 0.028, MSE = 0.01
subject 29: v0 = 86.26, k = 0.031, MSE = 0.00
subject 30: v0 = 88.35, k = 0.032, MSE = 0.01
subject 31: v0 = 87.59, k = 0.028, MSE = 0.00
subject 32: v0 = 87.90, k = 0.037, MSE = 0.09
subject 33: v0 = 84.37, k = 0.031, MSE = 0.00
subject 34: v0 = 85.88, k = 0.032, MSE = 0.00
subject 35: v0 = 85.53, k = 0.032, MSE = 0.01
subject 36: v0 = 83.40, k = 0.032, MSE = 0.01
subject 37: v0 = 86.35, k = 0.037, MSE = 0.11
subject 38: v0 = 79.91, k = 0.032, MSE = 0.01
subject 39: v0 = 85.62, k = 0.029, MSE = 0.00
subject 40: v0 = 85.60, k = 0.031, MSE = 0.00
subject 41: v0 = 86.42, k = 0.032, MSE = 0.01
subject 42: v0 = 84.90, k = 0.027, MSE = 0.01
subject 43: v0 = 87.15, k = 0.032, MSE = 0.00
subject 44: v0 = 81.64, k = 0.027, MSE = 0.01
subject 45: v0 = 87.58, k = 0.031, MSE = 0.00
subject 46: v0 = 82.66, k = 0.024, MSE = 0.02
subject 47: v0 = 88.35, k = 0.037, MSE = 0.11
subject 48: v0 = 83.87, k = 0.034, MSE = 0.03
subject 49: v0 = 83.54, k = 0.029, MSE = 0.00
subject 50: v0 = 87.04, k = 0.032, MSE = 0.00
subject 51: v0 = 82.67, k = 0.031, MSE = 0.00
subject 52: v0 = 83.27, k = 0.025, MSE = 0.02
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 53: v0 = 84.08, k = 0.036, MSE = 0.07
subject 54: v0 = 87.91, k = 0.035, MSE = 0.04
subject 55: v0 = 83.63, k = 0.019, MSE = 0.04
subject 56: v0 = 83.40, k = 0.023, MSE = 0.03
subject 57: v0 = 84.98, k = 0.036, MSE = 0.08
subject 58: v0 = 88.32, k = 0.034, MSE = 0.03
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 59: v0 = 82.08, k = 0.025, MSE = 0.02
subject 60: v0 = 86.55, k = 0.024, MSE = 0.03
subject 61: v0 = 85.16, k = 0.032, MSE = 0.01
subject 62: v0 = 85.18, k = 0.024, MSE = 0.02
subject 63: v0 = 86.37, k = 0.030, MSE = 0.00
subject 64: v0 = 85.07, k = 0.029, MSE = 0.00
subject 65: v0 = 84.85, k = 0.035, MSE = 0.06
subject 66: v0 = 84.30, k = 0.033, MSE = 0.01
subject 67: v0 = 88.06, k = 0.036, MSE = 0.08
subject 68: v0 = 87.70, k = 0.033, MSE = 0.02
subject 69: v0 = 84.96, k = 0.033, MSE = 0.02
subject 70: v0 = 86.41, k = 0.026, MSE = 0.01
subject 71: v0 = 85.45, k = 0.024, MSE = 0.02
subject 72: v0 = 81.49, k = 0.030, MSE = 0.00
subject 73: v0 = 83.34, k = 0.030, MSE = 0.00
subject 74: v0 = 82.40, k = 0.031, MSE = 0.00
subject 75: v0 = 83.74, k = 0.032, MSE = 0.00
subject 76: v0 = 86.06, k = 0.027, MSE = 0.01
subject 77: v0 = 88.30, k = 0.029, MSE = 0.00
subject 78: v0 = 85.50, k = 0.033, MSE = 0.02
subject 79: v0 = 84.61, k = 0.024, MSE = 0.02
subject 80: v0 = 85.92, k = 0.033, MSE = 0.01
subject 81: v0 = 84.83, k = 0.030, MSE = 0.00
subject 82: v0 = 83.61, k = 0.028, MSE = 0.00
subject 83: v0 = 87.29, k = 0.032, MSE = 0.01
subject 84: v0 = 84.32, k = 0.024, MSE = 0.02
subject 85: v0 = 88.26, k = 0.033, MSE = 0.02
subject 86: v0 = 86.83, k = 0.033, MSE = 0.01
subject 87: v0 = 84.54, k = 0.024, MSE = 0.02
subject 88: v0 = 91.47, k = 0.026, MSE = 0.01
subject 89: v0 = 81.25, k = 0.023, MSE = 0.03
subject 90: v0 = 81.40, k = 0.025, MSE = 0.02
subject 91: v0 = 87.81, k = 0.031, MSE = 0.00
subject 92: v0 = 82.99, k = 0.027, MSE = 0.01
subject 93: v0 = 88.16, k = 0.023, MSE = 0.03
subject 94: v0 = 81.63, k = 0.023, MSE = 0.03
subject 95: v0 = 83.84, k = 0.026, MSE = 0.02
subject 96: v0 = 84.69, k = 0.033, MSE = 0.01
subject 97: v0 = 85.31, k = 0.027, MSE = 0.01
subject 98: v0 = 85.96, k = 0.027, MSE = 0.01
subject 99: v0 = 82.42, k = 0.027, MSE = 0.01
</pre></div>
</div>
</div>
</div>
<p>We can plot the distributions of <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(k\)</span> across participants</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_df</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;v0&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_df</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_22_0.png" src="_images/module-02-01_Nonlinear-Modeling_22_0.png" />
</div>
</div>
<hr></div>
</div>
<div class="section" id="model-comparison">
<h2>Model comparison<a class="headerlink" href="#model-comparison" title="Permalink to this headline">¶</a></h2>
<p>Above, we can see that the hyperbolic model fits the data best, but typically the best fitting model isn’t so obvious. Thus, we can use methods such as <span class="math notranslate nohighlight">\(R^2\)</span> or the <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Bayesian Information Criterion</a> (<span class="math notranslate nohighlight">\(BIC\)</span>) to compare model fits. The model with the lowest <span class="math notranslate nohighlight">\(BIC\)</span> value is the best fitting model in a finite set of models.</p>
<p>The <span class="math notranslate nohighlight">\(BIC\)</span> penalizes free parameters (see constant term: <span class="math notranslate nohighlight">\(k*ln(n)\)</span>):</p>
<div class="math notranslate nohighlight">
\[ BIC = -2*ln(MSE) + p*ln(n)\]</div>
<p>Here, <span class="math notranslate nohighlight">\(n\)</span> is the total number of observations in your sample (e.g., sample size), <span class="math notranslate nohighlight">\(p\)</span> the number of parameters estimated by the model (we are estimating two parameters in our model: <span class="math notranslate nohighlight">\(v0\)</span> and <span class="math notranslate nohighlight">\(k\)</span>), and <span class="math notranslate nohighlight">\(MSE\)</span> is the mean sqauared error of the model. Remember that a lower <span class="math notranslate nohighlight">\(BIC\)</span> value is better; Adding the term <span class="math notranslate nohighlight">\(p*ln(n)\)</span> penalizes the model fit by the number of free parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_bic</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">mse</span><span class="p">,</span> <span class="n">num_params</span><span class="p">):</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_params</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bic</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the Bayesian Information Criterion (bic)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="n">calculate_bic</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v_mean</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> (BIC): </span><span class="si">{</span><span class="n">bic</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lin (BIC): -4.263
exp (BIC): -1.763
hyp (BIC): 0.730
</pre></div>
</div>
</div>
</div>
<p>We can now show that the hyperbolic model is the model with the lowest <span class="math notranslate nohighlight">\(BIC\)</span> value (out of the models tested above).</p>
<hr></div>
<div class="section" id="fitting-actual-data-to-models">
<h2>Fitting actual data to models<a class="headerlink" href="#fitting-actual-data-to-models" title="Permalink to this headline">¶</a></h2>
<p>Now that we’ve seen two examples of simulating data and model parameter recovery. Let’s try to fit actual data to these models.</p>
<p>We will use a subset of the data from <a class="reference external" href="https://www.nature.com/articles/s41562-017-0100">Vekaria et al. (2017)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First let&#39;s load in the data</span>

<span class="c1"># here, we are just going to download data from the web (no need to edit these lines, but try to figure out what they are doing)</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/Vekaria-et-al-2017_data.csv&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;subject&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          1   2   5  10  20  50  100
subject                             
102      85  85  85  85  85  65   85
106      85  85  -5   5   5   5    5
107      85  85  85  85  85   5    5
113      85  55  65  55  25  15    5
114      65  55  45  55  45  15   15
</pre></div>
</div>
</div>
</div>
<p>We can see that our data are formatted with participants as rows and amounts willing to forgo at each social distance as columns. To use our functions above, we will need to make sure our <span class="math notranslate nohighlight">\(v\)</span> data have shape <code class="docutils literal notranslate"><span class="pre">(n_subjects,</span> <span class="pre">7)</span></code>.</p>
<p>Let’s convert the pd.DataFrame to a np.array:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vekaria_data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vekaria_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(25, 7)
</pre></div>
</div>
</div>
</div>
<p>First, let’s fit all of the data together, with fixed intercepts and slopes, for both the hyperbolic model and the exponential model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fit1</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
               <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
               <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="c1"># arguments</span>
               <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
               <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># minimize MSE for exponential function using scipy.optimize.minimize</span>
<span class="n">fit2</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_exponential</span><span class="p">,</span> <span class="c1"># objective function</span>
               <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
               <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="c1"># arguments</span>
               <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
               <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fig, axes = plt.subplots()</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>    

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed (mean)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Hyperbolic&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fit2</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">fit1</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exponential&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_35_0.png" src="_images/module-02-01_Nonlinear-Modeling_35_0.png" />
</div>
</div>
<p>Based on this plot, we can clearly see how much better the hyperbolic model is at explaining the variance in the data. We can confirm this again using the <span class="math notranslate nohighlight">\(BIC\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the Bayesian Information Criterion (bic)</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;hyperbolic&#39;</span><span class="p">,</span> <span class="s1">&#39;exponential&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">fit1</span><span class="p">,</span> <span class="n">fit2</span><span class="p">]):</span>
    <span class="n">bic</span> <span class="o">=</span> <span class="n">calculate_bic</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vekaria_data</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> (BIC): </span><span class="si">{</span><span class="n">bic</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>hyperbolic (BIC): -6.567
exponential (BIC): -6.668
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">res_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    
    <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                   <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                   <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                   <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                   <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">res_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">: v0 = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, k = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, MSE = </span><span class="si">{</span><span class="n">fit</span><span class="o">.</span><span class="n">fun</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 102: v0 = 80.00, k = 0.000, MSE = 53.53
subject 106: v0 = 80.00, k = 0.301, MSE = 488.09
subject 107: v0 = 80.00, k = 0.024, MSE = 430.10
subject 113: v0 = 79.88, k = 0.074, MSE = 75.61
subject 114: v0 = 62.64, k = 0.033, MSE = 42.86
subject 116: v0 = 80.00, k = 0.000, MSE = 25.00
subject 119: v0 = 80.00, k = 0.021, MSE = 370.64
subject 120: v0 = 79.94, k = 0.087, MSE = 224.61
subject 121: v0 = 80.00, k = 0.000, MSE = 25.00
subject 122: v0 = 80.00, k = 0.003, MSE = 62.99
subject 123: v0 = 79.62, k = 0.110, MSE = 358.13
subject 124: v0 = 79.97, k = 0.062, MSE = 55.33
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 125: v0 = 80.00, k = 0.019, MSE = 294.43
subject 126: v0 = 80.00, k = 0.006, MSE = 820.72
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 127: v0 = 80.00, k = 0.030, MSE = 138.29
subject 128: v0 = 80.00, k = 0.000, MSE = 25.00
subject 132: v0 = 80.00, k = 0.024, MSE = 196.97
subject 135: v0 = 80.00, k = 0.056, MSE = 503.05
subject 136: v0 = 79.98, k = 0.089, MSE = 271.09
subject 137: v0 = 80.00, k = 0.021, MSE = 351.20
subject 138: v0 = 80.00, k = 0.024, MSE = 149.32
subject 139: v0 = 80.00, k = 0.220, MSE = 273.89
subject 141: v0 = 79.93, k = 0.083, MSE = 135.05
subject 143: v0 = 56.54, k = 0.036, MSE = 16.84
subject 147: v0 = 80.00, k = 0.361, MSE = 178.55
</pre></div>
</div>
</div>
</div>
<p>We can see that some participants did not do very well with model fitting. For most, this is because their “amounts willing to forgo” do not vary across social distances.</p>
<p>To account for this, let’s check which subjects these are.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="n">subj_v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subj_v</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;no variation for subject #</span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">subj_v</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>no variation for subject #116, [85 85 85 85 85 85 85]
no variation for subject #121, [85 85 85 85 85 85 85]
no variation for subject #128, [85 85 85 85 85 85 85]
</pre></div>
</div>
</div>
</div>
<p>Three participants sacrificed all of their resources for all social others. Let’s assign <code class="docutils literal notranslate"><span class="pre">k=0</span></code> and <code class="docutils literal notranslate"><span class="pre">v0=85</span></code> to these participants since there is no variation in their preferences. This is eqivalent to a straight horizontal line (no discounting) at <span class="math notranslate nohighlight">\(v=85\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a DataFrame, with columns corresponding to params [&#39;v0&#39;, k] and rows corresponding to subjects</span>
<span class="n">hyp_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">subj_id</span><span class="p">,</span> <span class="n">subj_v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">vekaria_data</span><span class="p">):</span>
    
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="n">subj_v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">subj_v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">subj_v</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">595</span><span class="p">:</span>
            
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">80</span> <span class="c1"># </span>
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;assigning k=0 for subject #</span><span class="si">{</span><span class="n">subj_id</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">subj_v</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    
        <span class="c1"># minimize MSE for hyperbolic function using scipy.optimize.minimize</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">mse_hyperbolic</span><span class="p">,</span> <span class="c1"># objective function</span>
                       <span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mf">.05</span><span class="p">),</span> <span class="c1"># estimated starting points</span>
                       <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">subj_v</span><span class="p">),</span> <span class="c1"># arguments</span>
                       <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">80</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                       <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;v0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">hyp_vekaria</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">subj_id</span><span class="p">,</span> <span class="s1">&#39;MSE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">fun</span>

<span class="n">res_vekaria</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">hyp_vekaria</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>assigning k=0 for subject #116, [85 85 85 85 85 85 85]
assigning k=0 for subject #121, [85 85 85 85 85 85 85]
assigning k=0 for subject #128, [85 85 85 85 85 85 85]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_vekaria</span><span class="p">[</span><span class="s1">&#39;v0&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;v0&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res_vekaria</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Number of Subjects&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-02-01_Nonlinear-Modeling_43_0.png" src="_images/module-02-01_Nonlinear-Modeling_43_0.png" />
</div>
</div>
<p>Yay! Now, we can use these data for subsequent analyses! Note the little variation in <span class="math notranslate nohighlight">\(v_0\)</span>. Also note that <span class="math notranslate nohighlight">\(k\)</span> is not parametric (e.g., not normally distributed), so we would need to conduct subsequent analyses using non-parametric approaches.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="module-02-00_Linear-Modeling.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Linear Modeling</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="module-02-02_Modeling-Exercises.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Modeling Exercises</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Shawn A. Rhoads<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KG3N20S55G"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('config', 'G-KG3N20S55G');
                </script>

  </body>
</html>