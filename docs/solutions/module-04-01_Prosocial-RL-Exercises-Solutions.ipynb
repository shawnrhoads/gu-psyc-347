{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amended-valentine",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/solutions/module-04-01_Prosocial-RL-Exercises-Solutions.ipynb\">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</a>\n",
    "\n",
    "# Prosocial RL Exercises Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-cambodia",
   "metadata": {},
   "source": [
    "We will now fit your behavioral data to the models developed during class (as well as a few others) and then compare the models to assess which model best explains the data. This exercise is a bit different from previous exercises. I will only provide you with minimal code/text to guide you through, but you should be able to complete it all on your own using the course resources, previous tutorials/exercises, previous papers, and previous lectures!\n",
    "\n",
    "**Once you complete this exercise, you will be well on your way to becoming a pro computational modeler!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-reynolds",
   "metadata": {},
   "source": [
    "<hr width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-ecology",
   "metadata": {},
   "source": [
    "Please download the data from [GitHub](), Canvas, or by using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "# create list of URLs\n",
    "urls = [f'https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/{x:02}_psyc-347-prosocial-learning.csv' for x in range(1,11)]\n",
    "\n",
    "# loop through list and download data\n",
    "for url in urls:\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    if os.path.isdir('static/data'):\n",
    "        filename = 'static/data/' + os.path.basename(url)\n",
    "    else:\n",
    "        filename = os.path.basename(url)\n",
    "    open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-rough",
   "metadata": {},
   "source": [
    "Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "filled-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize # finding optimal params in models\n",
    "from scipy import stats             # statistical tools\n",
    "import os                           # operating system tools\n",
    "import numpy as np                  # matrix/array functions\n",
    "import pandas as pd                 # loading and manipulating data\n",
    "import ipywidgets as widgets        # interactive display\n",
    "import matplotlib.pyplot as plt     # plotting\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2021)                # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hawaiian-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will load the data into memory (assuming that\n",
    "# the data are downloaded)\n",
    "def load_subjects():\n",
    "    '''\n",
    "    input: n/a\n",
    "    output: dictionary of DataFrames containing the data\n",
    "    '''\n",
    "        \n",
    "    if os.path.isdir('static/data'):\n",
    "        files = [f'static/data/{x:02}_psyc-347-prosocial-learning.csv' for x in range(1,11)]\n",
    "    else:\n",
    "        files = [f'{x:02}_psyc-347-prosocial-learning.csv' for x in range(1,11)]\n",
    "    \n",
    "    subject_data = {}\n",
    "    for index, file in enumerate(files):\n",
    "        df = pd.read_csv(file, index_col='subject')\n",
    "        subject_data[index] = df_filtered = df[df['outcomeDescr'] != 'practice'][['block',\n",
    "                                                                                  'trial_num',\n",
    "                                                                                  'true_accuracy',\n",
    "                                                                                  'outcome',\n",
    "                                                                                  'outcomeDescr',\n",
    "                                                                                  'cumulativePts_self',\n",
    "                                                                                  'cumulativePts_social']]\n",
    "        \n",
    "    return subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load in our data using the function above\n",
    "# feel free to adjust `how_many` (the default is all 11 subjects)\n",
    "subject_data = load_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-ethnic",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "#### 4 conditions/blocks\n",
    "- self, win\n",
    "- self, avoid loss\n",
    "- social, win\n",
    "- social, avoid loss\n",
    "\n",
    "#### Each block contains 24 trials\n",
    "- 2 stimuli per trial (counterbalanced wrt side)\n",
    "- outcomes associated with each stimulus is probabilistic (75%, 25%)\n",
    "\n",
    "#### Data output key\n",
    "- `condition`: (play for self); (play for next participant)\n",
    "- `goal`: (win) or (avoid loss)\n",
    "- `trial_num`: order in which trials are displayed within a block (0-23)\n",
    "- `true_accuracy`: 1 if selected stimulus with highest probability of winning or avoid losing\n",
    "- `outcome`: outcome for trial (`+1`, `0`, `-1`); blank if missed\n",
    "- `outcomeDescr`: text description of outcome (practice, social win, social avoid win, social loss, social avoidloss, self win, self avoid win, self loss, self avoidloss)\n",
    "- `cumulativePts_self`: running total of points for self\n",
    "- `cumulativePts_social`: running total of points for social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saving-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>true_accuracy</th>\n",
       "      <th>outcome</th>\n",
       "      <th>outcomeDescr</th>\n",
       "      <th>cumulativePts_self</th>\n",
       "      <th>cumulativePts_social</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>social_win</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>social avoid win</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>social_win</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>social win</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>social_win</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>social win</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>social_win</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>social win</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>social_win</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>social avoid win</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>self_avoidloss</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self avoid loss</td>\n",
       "      <td>2100</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>self_avoidloss</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self avoid loss</td>\n",
       "      <td>2100</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>self_avoidloss</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self avoid loss</td>\n",
       "      <td>2100</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>self_avoidloss</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>self lose</td>\n",
       "      <td>2000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>self_avoidloss</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>self lose</td>\n",
       "      <td>1900</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  block  trial_num  true_accuracy  outcome      outcomeDescr  \\\n",
       "subject                                                                        \n",
       "1.0          social_win          0            0.0      0.0  social avoid win   \n",
       "1.0          social_win          1            1.0      1.0        social win   \n",
       "1.0          social_win          2            1.0      1.0        social win   \n",
       "1.0          social_win          3            1.0      1.0        social win   \n",
       "1.0          social_win          4            1.0      0.0  social avoid win   \n",
       "...                 ...        ...            ...      ...               ...   \n",
       "1.0      self_avoidloss         19            1.0      0.0   self avoid loss   \n",
       "1.0      self_avoidloss         20            1.0      0.0   self avoid loss   \n",
       "1.0      self_avoidloss         21            1.0      0.0   self avoid loss   \n",
       "1.0      self_avoidloss         22            1.0     -1.0         self lose   \n",
       "1.0      self_avoidloss         23            0.0     -1.0         self lose   \n",
       "\n",
       "         cumulativePts_self  cumulativePts_social  \n",
       "subject                                            \n",
       "1.0                    1000                  1000  \n",
       "1.0                    1000                  1100  \n",
       "1.0                    1000                  1200  \n",
       "1.0                    1000                  1300  \n",
       "1.0                    1000                  1300  \n",
       "...                     ...                   ...  \n",
       "1.0                    2100                  1300  \n",
       "1.0                    2100                  1300  \n",
       "1.0                    2100                  1300  \n",
       "1.0                    2000                  1300  \n",
       "1.0                    1900                  1300  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view data from first subject\n",
    "display(subject_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-diversity",
   "metadata": {},
   "source": [
    "<hr width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attractive-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_positions(list_of_elems, element):\n",
    "    ''' Returns the indexes of all occurrences of give element in\n",
    "    the list- listOfElements '''\n",
    "    index_pos_list = []\n",
    "    index_pos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            index_pos = list_of_elems.index(element, index_pos)\n",
    "            # Add the index position in list\n",
    "            index_pos_list.append(index_pos)\n",
    "            index_pos += 1\n",
    "        except ValueError as e:\n",
    "            break\n",
    "            \n",
    "    return index_pos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-there",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprising-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed\n",
    "def Simple_1a1t(params, choices, outcomes, block, plot=False):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 2 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha, theta = params \n",
    "    \n",
    "    if np.isnan(alpha) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    delta = r[t] - Q[int(c[t])]\n",
    "                    Q[int(c[t])] = Q[int(c[t])] + alpha * delta\n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compact-diary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example for testing function\n",
    "behavior = subject_data[9]\n",
    "params = [.12,2.11]\n",
    "choices, outcomes, block = behavior.true_accuracy, behavior.outcome, behavior.block\n",
    "subj_negll = Simple_1a1t(params, choices, outcomes, block, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed\n",
    "def Social_1a1t(params, choices, outcomes, block, plot=False):\n",
    "    # 1 alpha_self (where alpha_other = 1 - alpha_self) + 1 theta\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 2 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha_self, theta = params \n",
    "    alpha_other = 1 - alpha_self\n",
    "    \n",
    "    if np.isnan(alpha_self) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r]) \n",
    "                \n",
    "                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    delta = r[t] - Q[int(c[t])]\n",
    "                    \n",
    "                    if 'self' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_self * delta\n",
    "                    elif 'social' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_other * delta\n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model1 (8 out of 30 points)\n",
    "def Social_2a1b1t(params, choices, outcomes, block, plot=False):\n",
    "    # 1 alpha_self + 1 alpha_other + 1 beta + 1 theta\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 4 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha_self, alpha_other, beta, theta = params \n",
    "    \n",
    "    if np.isnan(alpha_self) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r]) \n",
    "                \n",
    "                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    delta = beta * r[t] - Q[int(c[t])]\n",
    "                    \n",
    "                    if 'self' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_self * delta\n",
    "                    elif 'social' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_other * delta\n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model2 (8 out of 30 points)\n",
    "def Valence_2a1t(params, choices, outcomes, block):\n",
    "    # 1 alpha_positive + 1 alpha_negative + 1 theta\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 3 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha_positive, alpha_negative, theta = params \n",
    "    \n",
    "    if np.isnan(alpha_self) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r]) \n",
    "                \n",
    "                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    delta = beta * r[t] - Q[int(c[t])]\n",
    "                    \n",
    "                    if 'win' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_positive * delta\n",
    "                    elif 'avoidloss' in condition:\n",
    "                        Q[int(c[t])] = Q[int(c[t])] + alpha_negative * delta\n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model3 (8 out of 30 points)\n",
    "def Social_1a2b1t(params, choices, outcomes, block, plot=False):\n",
    "    # 1 alpha + 1 beta_self + 1 beta_other + 1 theta\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 4 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha, beta_self, beta_other, theta = params \n",
    "    \n",
    "    if np.isnan(alpha_self) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r]) \n",
    "                \n",
    "                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    if 'self' in condition:\n",
    "                        delta = beta_self * r[t] - Q[int(c[t])]\n",
    "                    elif 'social' in condition:\n",
    "                        delta = beta_other * r[t] - Q[int(c[t])]\n",
    "\n",
    "                    Q[int(c[t])] = Q[int(c[t])] + alpha * delta\n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus (not required for exercise)\n",
    "def SocialValence_4a1t(params, choices, outcomes, block, plot=False):\n",
    "    # 1 alpha_self_pos + 1 alpha_self_neg +\n",
    "    # 1 alpha_other_pos + 1 alpha_other_neg + 1 theta\n",
    "    '''\n",
    "    Inputs:\n",
    "        - params: list of 5 guesses (float) for each parameter (alpha, theta)\n",
    "        - choices: list of 96 choices (int) on each trial (0, 1)\n",
    "        - outcomes: list of 96 outcomes (int) on each trial (-1, 0, 1)\n",
    "        - block: list of 96 conditions (string) on each trial (self_win, self_avoidloss, social_win, social_avoidloss)\n",
    "    Outputs:\n",
    "        - negLL: negative loglikelihood computed\n",
    "                 from the choice probabilities (float)\n",
    "    '''\n",
    "    alpha_self_pos, alpha_self_neg, alpha_other_pos, alpha_other_neg, theta = params \n",
    "    \n",
    "    if np.isnan(alpha_self_pos) or np.isnan(alpha_self_neg) or np.isnan(alpha_other_pos) or np.isnan(alpha_other_neg) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    else:\n",
    "        blocks = list(block)\n",
    "\n",
    "        # extracts list of four strings corresponding to conditions\n",
    "        unique_conditions = list(set(block))\n",
    "\n",
    "        # init choice probs\n",
    "        choiceProb = np.zeros((len(blocks)), dtype = float) \n",
    "        Q_out = {}\n",
    "\n",
    "        count = 0\n",
    "        for condition in unique_conditions:\n",
    "\n",
    "            T_temp = blocks.count(condition)    \n",
    "            Q = [0.5, 0.5] # Q at trial 0\n",
    "            Q_stored = np.zeros((2, T_temp), dtype = float) \n",
    "\n",
    "            cur_indices = get_index_positions(blocks, condition)\n",
    "            c, r = np.array(choices)[cur_indices], np.array(outcomes)[cur_indices]\n",
    "\n",
    "            # check if self vs social\n",
    "            if 'self' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r]) \n",
    "                \n",
    "                \n",
    "            elif 'social' in condition:\n",
    "                # check if win vs avoid loss\n",
    "                if 'win' in condition:\n",
    "                    r = r\n",
    "                elif 'avoidloss' in condition:\n",
    "                    r = np.array([x+1 for x in r])\n",
    "            \n",
    "            # loop through trials within condition\n",
    "            for t in range(T_temp):       \n",
    "\n",
    "                if np.isnan(c[t]):\n",
    "                    #don't update\n",
    "                    choiceProb[count] = np.nan\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                else:\n",
    "                    # compute choice probabilities for k=2\n",
    "                    # use the softmax rule\n",
    "                    ev = np.exp(theta*np.array(Q))\n",
    "                    sum_ev = np.sum(ev)\n",
    "                    p = ev / sum_ev\n",
    "\n",
    "                    # compute choice probability for actual choice\n",
    "                    choiceProb[count] = p[int(c[t])]\n",
    "\n",
    "                    # update values\n",
    "                    delta = r[t] - Q[int(c[t])]\n",
    "\n",
    "                    if 'self' in condition:\n",
    "                        if 'win' in condition:\n",
    "                            Q[int(c[t])] = Q[int(c[t])] + alpha_self_pos * delta\n",
    "                        elif 'avoidloss' in condition:\n",
    "                            Q[int(c[t])] = Q[int(c[t])] + alpha_self_neg * delta\n",
    "\n",
    "                    elif 'social' in condition:\n",
    "                        if 'win' in condition:\n",
    "                            Q[int(c[t])] = Q[int(c[t])] + alpha_other_pos * delta\n",
    "                        elif 'avoidloss' in condition:\n",
    "                            Q[int(c[t])] = Q[int(c[t])] + alpha_other_neg * delta                    \n",
    "\n",
    "                    # store Q_t+1\n",
    "                    Q_stored[:,t] = Q\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            Q_out[condition] = Q_stored\n",
    "            \n",
    "        negLL = -np.nansum(np.log(choiceProb))\n",
    "        \n",
    "        if plot: #plot mean across 4 blocks\n",
    "            Q0 = np.mean(np.stack((Q_out['self_win'][0], Q_out['social_win'][0], Q_out['self_avoidloss'][0], Q_out['social_avoidloss'][0]),axis=0),axis=0)\n",
    "            Q1 = np.mean(np.stack((Q_out['self_win'][1], Q_out['social_win'][1], Q_out['self_avoidloss'][1], Q_out['social_avoidloss'][1]),axis=0),axis=0)\n",
    "\n",
    "            plt.plot(range(T_temp),Q0)\n",
    "            plt.plot(range(T_temp),Q1)\n",
    "            plt.title('Mean Q across conditions')\n",
    "            plt.xlabel('trial')\n",
    "            plt.ylabel('Q')\n",
    "            plt.show()\n",
    "        \n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BIC for each Model and Plot (6 out of 30 points)\n",
    "def calculate_bic(n, nll, num_params):\n",
    "    bic = -2 * nll + num_params * np.log(n)\n",
    "    return bic\n",
    "\n",
    "def plot_bic(df0a, df0b, df1, df2, df3):\n",
    "    # 96 trials across 11 subjects\n",
    "    all_num_trials = 96 * 11\n",
    "\n",
    "    #init list to input bic values\n",
    "    Bic_list = []\n",
    "\n",
    "    all_mods = [df0a, df0b, df1, df2, df3]\n",
    "    all_num_params = [2, 2, 4, 3, 4]\n",
    "\n",
    "    # get integrated BIC for each model\n",
    "    for mod, num_params in zip(all_mods, all_num_params):\n",
    "        bic_temp = calculate_bic(n= all_num_trials, nll=np.nansum(mod['NLL'].values), num_params=num_params)\n",
    "        bic_list.append(bic_temp)\n",
    "\n",
    "    #plot these values:\n",
    "    plt.bar(range(0,len(all_mods)), bic_list)\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"BIC Score\")\n",
    "    plt.title(\"BIC Scores for Different Models\")\n",
    "\n",
    "    plt.xticks(range(0,len(all_mods)), [\"df0a\", \"df0b\", \"df1\", \"df2\", \"df3\"])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
