{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intimate-oxygen",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-03-02_RL-Exercises.ipynb\">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</a>\n",
    "\n",
    "# RL Exercises\n",
    "\n",
    "These exercises were inspired by and adapted from [Models of Learning](http://www.hannekedenouden.ruhosting.nl/RLtutorial/Instructions.html) by Jill O'Reilly and Hanneke den Ouden, [NSCS 344 - Modeling the Mind](http://u.arizona.edu/~bob/web_NSCS344) by Robert C. Wilson, [NSCI 526 - Tutorial 2 (Reinforcement Learning)](https://github.com/shawnrhoads/gu-nsci-526) by Shawn Rhoads, the [Gambling Game tutorial](https://github.com/cloudssty), and the [Neuromatch Academy tutorials](https://github.com/NeuromatchAcademy/course-content) [[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-purse",
   "metadata": {},
   "source": [
    "In these exercises, we will fit learning behavior to the Rescorla Wagner model of Reinforcement Learning. The data can be downloaded from [GitHub](https://github.com/shawnrhoads/gu-psyc-347/raw/editing/docs/static/data/RL-Exercises-Data.zip) or by simply running the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-president",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "**Part 1**\n",
    "\n",
    "1. [Getting to know your stimuli](#getting-to-know-your-stimuli)\n",
    "2. [Exploring behavior](#exploring-behavior)\n",
    "3. [Exploring outcomes](#exploring-outcomes)\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "4. [Defining a likelihood function](#defining-a-likelihood-function)\n",
    "5. [Minimizing the negative loglikelihood](#minimizing-the-negative-loglikelihood)\n",
    "6. [Comparing results with your predictions](#comparing-results-with-your-predictions)\n",
    "\n",
    "#### Key\n",
    "- `# [INSERT CODE BELOW]` : indicates where you should insert your own code, feel free to replace with a comment of your own\n",
    "- `...`: indicates a location where you should insert your own code\n",
    "- `raise NotImplementedError(\"Student exercise: *\")` : delete this line once you have added your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-montgomery",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-colon",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "You will break out in groups of 2-3 to discuss the following questions (<font color='red'>highlighted in red font</font>) and implement code to answer them. I have prepared a few functions that will help you along the way.\n",
    "\n",
    "Then, we will re-group with the entire class to discuss what we've learned. Please remember to save your work. This will count towards your Jupyter Notebook Exercise #3 grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import our packages\n",
    "\n",
    "from scipy.optimize import minimize # finding optimal params in models\n",
    "from scipy import stats             # statistical tools\n",
    "import os                           # operating system tools\n",
    "import numpy as np                  # matrix/array functions\n",
    "import pandas as pd                 # loading and manipulating data\n",
    "import ipywidgets as widgets        # interactive display\n",
    "import matplotlib.pyplot as plt     # plotting\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2021)                # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "checked-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will load the data into memory (assuming that\n",
    "# the data are downloaded)\n",
    "def load_subjects(how_many=15):\n",
    "    '''\n",
    "    input: number of subjects' data to load from 1-14\n",
    "    output: dictionary of DataFrames containing the data\n",
    "    '''\n",
    "    \n",
    "    assert (how_many > 0) and (how_many <= 15), \"0 < how_many < 15\"\n",
    "    files = urls = [f'https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/sub-{x:02}_RLdata.csv' for x in range(0,how_many)]\n",
    "    \n",
    "    subject_data = {}\n",
    "    for index, file in enumerate(files):\n",
    "        subject_data[index] = pd.read_csv(file, index_col=0)\n",
    "    \n",
    "    return subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load in our data using the function above\n",
    "# feel free to adjust `how_many` (the default is all 15 subjects)\n",
    "subject_data = load_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-restriction",
   "metadata": {},
   "source": [
    "### 1. Getting to know your stimuli\n",
    "\n",
    "Subjects played a few rounds of the two-armed bandit task, in which they learned the reward probability distribution of two slot machines (**stim_A** and **stim_B**) through trial-and-error. \n",
    "\n",
    "<font color=\"red\">1a. How many trials did each subject complete?</font> (*Hint: explore the Dictionary of DataFrames*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [INSERT CODE BELOW]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-mobile",
   "metadata": {},
   "source": [
    "**ANSWER 1a: *insert your answer here*** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-emperor",
   "metadata": {},
   "source": [
    "Each slot machine was associated with a different mean probability (i.e., **stim_A** yielded rewards according to a constant probability and **stim_B** yielded rewards according to a different constant probability). \n",
    "\n",
    "<font color=\"red\">1b. What were the probabilities of each stimulus?<br>\n",
    "1c. Did **stim_A** have the same probability for every subject? **stim_B**? Why or why not?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-thunder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [INSERT CODE BELOW]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-dress",
   "metadata": {},
   "source": [
    "**ANSWER 1b: *insert your answer here***\n",
    "\n",
    "**ANSWER 1c: *insert your answer here***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-letter",
   "metadata": {},
   "source": [
    "### 2. Exploring behavior\n",
    "\n",
    "People learn (or don't) in many different ways. Some people are extremely sensitive when outcomes aren't what they expected. Others aren't willing to update their behaviors so quickly.\n",
    "\n",
    "People also make decisions differently. Some people are more explorative and are event willing to try a riskier action just to see what happens. Others are more \"deterministic\" with their actions tend to stick with what they know is best.\n",
    "\n",
    "While there are plenty more ways people vary in their learning and decision-making behavior, we are going to explore these two aspects. \n",
    "\n",
    "*Hint: please use the `plot_behavior()` function to explore different aspects of subjects' behavior and outcomes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_behavior(subject_data, subject_id, choices=False, outcomes=False, probability=False):\n",
    "    '''\n",
    "    input: \n",
    "        subject_data: dictionary containing\n",
    "        subject_id: integer from 0-14 corresponding to an ID number\n",
    "        choices: boolean indicating whether to plot choices or not\n",
    "        outcomes: boolean indicating whether to plot outcomes or not\n",
    "        probability: boolean indicating whether to plot the mean reward over trials for both stimuli or not\n",
    "    output:\n",
    "        plot of behavior\n",
    "    '''\n",
    "    assert type(subject_data) is dict, \"`subject_data` should be a dictionary, run the `load_subjects()` function above to load the data into memory\"\n",
    "    assert type(subject_id) is int and subject_id >= 0 and subject_id <= 14, \"`subject_id` should be an integer between 0 and 14\"\n",
    "    \n",
    "    data = subject_data[subject_id]\n",
    "    \n",
    "    if probability:\n",
    "        plt.axhline(np.mean(data[data.choice==0].outcome), color=\"orange\", alpha=.4, label=data.columns[0])\n",
    "        plt.axhline(np.mean(data[data.choice==1].outcome), color=\"purple\", alpha=.4, label=data.columns[1])\n",
    "        \n",
    "    if outcomes:\n",
    "        plt.plot(range(len(data)), data.outcome, 'r--', alpha=.6, label='outcome')\n",
    "    if choices:\n",
    "        if np.mean(data.choice) < .5:\n",
    "            choice_data = [0 if x == 1 else 1 for x in data.choice]\n",
    "        else:\n",
    "            choice_data = [x for x in data.choice]\n",
    "        plt.plot(range(len(data)), choice_data, '+', label='choice')\n",
    "    \n",
    "    plt.xlabel('trials')\n",
    "    plt.ylabel('outcome')\n",
    "    plt.title(f'Behavior from subject #{subject_id}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-native",
   "metadata": {},
   "source": [
    "Plot everyone's behavior and answer the following questions (*pro-tip: there's way to plot everyone's data using only two lines of code; can you figure it out?*).\n",
    "<br><br>\n",
    "\n",
    "<font color=\"red\">\n",
    "    2a. Which subjects were most sensitive to previous unexpected outcomes? In other words, who changed their decisions most often after a prediction error? List the subject ID numbers. Describe which aspect(s) of the data led you to this conclusion. What parameter from the Rescorla-Wagner Model captures this tendency?<br>\n",
    "    2b. Which subjects were least explorative in their behavior? List the subject ID numbers. Describe which aspect(s) of the data led you to this conclusion. What parameter from the Rescorla-Wagner Model captures this tendency?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-computer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [INSERT CODE BELOW]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-madrid",
   "metadata": {},
   "source": [
    "**ANSWER 2a: *insert your answer here***\n",
    "\n",
    "**ANSWER 2b: *insert your answer here***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-honduras",
   "metadata": {},
   "source": [
    "### 3. Exploring outcomes\n",
    "\n",
    "<font color=\"red\">Earlier, we learned that the reward probabilities of each stimulus were fixed, how do these values compare with the actual mean reward over trials across subjects (according to their choices)? Are they similar? Why or why not?</font> (*Hint: see plots above and/or explore different subjects' \"outcome\" column*)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [INSERT CODE BELOW]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-donna",
   "metadata": {},
   "source": [
    "**ANSWER 3: *insert your answer here***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-episode",
   "metadata": {},
   "source": [
    "Great job! Don't forget to save any of your work. It will also be useful for **Part 2**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-virtue",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-electricity",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Now that we have explored the data and gotten a sense about participants' behaviors during the task, let's estimate models that explain their learning!\n",
    "\n",
    "We will:\n",
    "- Define a function that computes the negative loglikelihood given the data and Rescorla-Wagner Model \n",
    "- Implement an minimization algorithm that loops through possible combinations of $\\alpha$ and $\\theta$ for each subject in order to find the parameters that minimize the negative loglikelihood. Each subject ($i$) will have a separate set of parameters $\\alpha_i$ and $\\theta_i$, which respectively correspond to the learning rate and inverse temperature \n",
    "- Compare the estimated parameter values for $\\alpha_i$ and $\\theta_i$ to your initial predictions in Questions [#2a-b](#2.-Exploring-behavior)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-population",
   "metadata": {},
   "source": [
    "### 4. Defining a likelihood function\n",
    "\n",
    "Recall that our goal is to find the parameter values of a model that maximize the likelihood of the data. In the Rescorla-Wagner case, we want to maximize the likelihood (a.k.a. minimize the loglikelihood) of the data given parameter values ($\\alpha$ and $\\theta$) of the model.\n",
    "\n",
    "In the Rescorla-Wagner Model, the likelihood of the data are given by the probability of making a choice on a give trial, $p(c_t)$. \n",
    "\n",
    "That is, participants use the stimuli values to guide their decisions, choosing the most valuable option most frequently, but occasionally making 'mistakes' (or exploring) by choosing a low value option. One choice rule with these properties is known as the **'softmax' choice rule**, which chooses option $k$ with probability:\n",
    "\n",
    "$$\n",
    "p^k_t = \\frac{\\exp(\\theta Q^k_t)}{\\sum_{i=1}^K \\exp(\\theta Q^i_t)}\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the 'inverse temperature' parameter that controls the level of stochasticity in the choice, ranging from $\\theta = 0$ for completely random responding and $\\theta = \\infty$ for deterministically choosing the highest value option.\n",
    "\n",
    "The value of each stimulus $k$, $Q^k_t$ is updated in response to reward $r_t$ according to:\n",
    "\n",
    "$$\n",
    "Q^k_{t+1} = Q^k_t + \\alpha (r_t - Q^k_t)\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate, which is bounded between 0 and 1 and captures the extent to which the prediction error, $(r_t - Q^k_t)$, updates the value (i.e., a higher $\\alpha$ value will put greater weight on the prediction error). For simplicity, we assume that the initial value, $Q^k_0=0$, although it is possible to treat the $Q^k_0$ as a free parameter of the model (this is also the intercept).\n",
    "\n",
    "Combining the learning and decision rules gives a simple model of decision making in this task with two free parameters: the learning rate, $\\alpha$, and the inverse temperature $\\theta$.\n",
    "\n",
    "Thus, for any given ($\\alpha$ and $\\theta$) of the model, the negative loglikelihood $negative \\log \\mathcal{L}$ will be computed as:\n",
    "\n",
    "$$\n",
    "negative \\log \\mathcal{L} = -\\sum_{t=1}^T \\log p(c_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-surrey",
   "metadata": {},
   "source": [
    "Below we will define a function that computes the negative loglikelihood given the data and Rescorla-Wagner Model (see [Intro to Python](https://shawnrhoads.github.io/gu-psyc-347/module-01-01_Intro-to-Python.html) for functions, [Modeling Exercises](https://shawnrhoads.github.io/gu-psyc-347/module-02-02_Modeling-Exercises.html) and [Models of Learning](https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html) for negative loglikelihood, and [Models of Learning](https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html) for the Rescorla-Wagner Model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-replacement",
   "metadata": {},
   "source": [
    "```\n",
    "# fill in the `...` below to estimate model params for each subject\n",
    "\n",
    "# [INSERT CODE BELOW]\n",
    "raise NotImplementedError(\"Student exercise: complete the code below to define that computes the negative loglikelihood for the Rescorla-Wagner Model of Learning, then delete this line\")\n",
    "\n",
    "def negll_RescorlaWagner(params, choices, outcomes):\n",
    "    \n",
    "    alpha, theta = params \n",
    "    \n",
    "    if np.isnan(alpha) or np.isnan(theta): # check inputs\n",
    "        return np.inf\n",
    "    \n",
    "    else:\n",
    "        c, r = choices, outcomes \n",
    "\n",
    "        T = len(c) \n",
    "        Q = [0.5, 0.5] # Q at trial 0\n",
    "        Q_stored = np.zeros((2, T), dtype = float) \n",
    "        choiceProb = np.zeros((T), dtype = float) \n",
    "\n",
    "        for t in range(T): # add comment\n",
    "\n",
    "            # compute choice probabilities for k=2\n",
    "            # use the softmax rule\n",
    "            ev = np.exp(theta*np.array(Q))\n",
    "            sum_ev = np.sum(ev)\n",
    "            p = ev / sum_ev\n",
    "\n",
    "            # compute choice probability for actual choice\n",
    "            choiceProb[t] = p[c[t]] \n",
    "\n",
    "            # update values\n",
    "            delta = r[t] - Q[c[t]]\n",
    "            Q[c[t]] = Q[c[t]] + alpha * ...\n",
    "\n",
    "            # store Q_t+1\n",
    "            Q_stored[:,t] = Q\n",
    "\n",
    "        negLL = -np.sum(np.log(choiceProb)) \n",
    "    \n",
    "        return negLL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-gross",
   "metadata": {},
   "source": [
    "Let's develop an intuition for how this function works. Make a guess for subejct #3's $\\alpha$ and $\\theta$ to compute the negative loglikelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-lounge",
   "metadata": {},
   "source": [
    "```\n",
    "# fill in the `...` below to make guess for alpha and theta for subject #3\n",
    "# then, fill in the inputs for the function\n",
    "\n",
    "# [INSERT CODE BELOW]\n",
    "raise NotImplementedError(\"Student exercise: make guess for alpha and theta to compute the negative loglikelihood, then delete this line\")\n",
    "\n",
    "alpha_guess = ... #number between 0-1\n",
    "theta_guess = ... #number between 1-8\n",
    "subj3_choices = subject_data[3].choice\n",
    "subj3_outcomes = subject_data[3].outcome\n",
    "\n",
    "# compute the negative ll\n",
    "subj3_negll = negll_RescorlaWagner([..., ...], subj3_choices, subj3_outcomes)\n",
    "print(f'given alpha={alpha_guess} and theta={theta_guess}, the negative loglikelihood is {subj3_negll:.2f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-andrews",
   "metadata": {},
   "source": [
    "### 5. Minimizing the negative loglikelihood\n",
    "\n",
    "Now that we have a function, implement an minimization algorithm that loops through possible combinations of $\\alpha$ and $\\theta$ for each subject in order to find the parameters that minimize the negative loglikelihood. Each subject ($i$) will have a separate set of parameters $\\alpha_i$ and $\\theta_i$, which respectively correspond to the learning rate and inverse temperature (see [Models of Learning](https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html)). \n",
    "\n",
    "Importantly, we will store these parameters in a Pandas DataFrame with 15 rows corresponding to subjects, and 2 columns corresponding to $\\alpha$ and $\\theta$ (see [Working with Data](https://shawnrhoads.github.io/gu-psyc-347/module-01-02_Working-with-Data.html) for more on Pandas DataFrames)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-tower",
   "metadata": {},
   "source": [
    "```\n",
    "# fill in the `...` below to estimate model params for each subject\n",
    "\n",
    "# [INSERT CODE BELOW]\n",
    "raise NotImplementedError(\"Student exercise: complete the code below to estimate model parameters for each subject, then delete this line\")\n",
    "\n",
    "#initialize dataframe to store results\n",
    "df = pd.DataFrame(index=range(0,len(subject_data)), columns=['alpha','theta'])\n",
    "\n",
    "# loop through subjects\n",
    "for index, behavior in enumerate(subject_data.values()):\n",
    "    ..., ... = behavior.choice, behavior.outcome\n",
    "    \n",
    "    # gradient descent to minimize neg LL\n",
    "    res_nll = np.inf # set initial neg LL to be inf\n",
    "\n",
    "    # guess several different starting points for alpha, theta\n",
    "    for alpha_guess in np.linspace(0,1,3):\n",
    "        for theta_guess in np.linspace(1,10,3):\n",
    "\n",
    "            # guesses for alpha, theta will change on each loop\n",
    "            init_guess = (..., ...)\n",
    "\n",
    "            # minimize neg LL\n",
    "            result = minimize(..., \n",
    "                              ..., \n",
    "                              (c, o), \n",
    "                              bounds=((0,1),(0,10)))\n",
    "\n",
    "            # if current negLL is smaller than the last negLL,\n",
    "            # then store current data\n",
    "            if result.fun < res_nll and result.success:\n",
    "                res_nll = ...\n",
    "                param_fits = ...\n",
    "\n",
    "    # also, compute BIC\n",
    "    BIC = len(init_guess) * np.log(len(c)) + 2*res_nll\n",
    "    \n",
    "    #store in dataframe\n",
    "    df.at[index, 'alpha'] = param_fits[0]\n",
    "    df.at[index, 'theta'] = param_fits[1]\n",
    "    \n",
    "    print(fr'subject {index:02}: alpha={param_fits[0]:.2f}, theta={param_fits[1]:.2f}; negLL={res_nll:.2f}; BIC={BIC:.2f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-nation",
   "metadata": {},
   "source": [
    "### 6. Comparing results with your predictions\n",
    "\n",
    "How were your predictions? <font color=\"red\">Do these parameters somewhat map onto what you expected solely based on their behavior?</font> It's okay if they didn't!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-graduate",
   "metadata": {},
   "source": [
    "**ANSWER 6: *insert your answer here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, please convert this cell to a Markdown cell.\n",
    "\n",
    "# Create a Heading named \"Notebook Feedback,\" then delete this text \n",
    "# and provide 1-2 sentences about your experience with this \n",
    "# Jupyter Notebook (e.g., Did you enjoy the exercises? Were \n",
    "# they too easy/difficult? Would you have like to see \n",
    "# anything different? Were you able to apply some skills we learned during\n",
    "# class? Anything still confusing?). Finally, please rate your experience\n",
    "# from (0) \"did not enjoy at all\" to (10) \"enjoyed a great deal.\" Only your\n",
    "# instructor will see these responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-seminar",
   "metadata": {},
   "source": [
    "Please save this file as an .html file by clicking on **'File > Download As > HTML (.html)'**\n",
    "\n",
    "Then, save the file as **\"Lastname_Exercise03.html\"** and submit on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-writer",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "See the solutions at the following links:\n",
    "- <a href=\"https://shawnrhoads.github.io/gu-psyc-347/solutions/module-03-02_RL-Exercises-Solutions.html\" target=\"_blank\">Jupyter Book</a> \n",
    "- <a href=\"https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/solutions/module-03-02_RL-Exercises-Solutions.ipynb\" target=\"_blank\">Google Colaboratory</a> "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": []
  },
  "execution": {
   "allow_errors": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
