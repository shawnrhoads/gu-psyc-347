{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-01-02_Working-with-Data.ipynb\">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</a>\n",
    "\n",
    "# Working with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Data using Pandas\n",
    "In this first section, we will use the Pandas package to explore and describe data from [O'Connell, K., Berluti, K., Rhoads, S. A., & Marsh, A. A. (2021)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0244974). Reduced social distancing during the COVID-19 pandemic is associated with antisocial behaviors in an online United States sample. PLoS ONE.\n",
    "\n",
    "This study assessed whether social distancing behaviors (early in the COVID-19 pandemic) was associated with self-reported antisocial behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember: Python requires you to explictly \"import\" libraries before their functions are available to use. We will always specify our imports at the beginning of each notebook.\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will load a dataset as a `pandas.DataFrame`, and investigate its attributes. We will see `N` rows for each subject, and `M` columns for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we are just going to download data from the web\n",
    "url = 'https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/OConnell_COVID_MTurk_noPII_post_peerreview.csv'\n",
    "\n",
    "# load data specified in `filename` into dataframe `df`\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check type of df\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows and columns are in df?\n",
    "print(df.values.shape) # N x M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we will have 131 rows (usually subjects, but can be multiple observations per subject) and 126 columns (usually variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's output the first 5 rows of the df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create our own dataframe. For example, here's a dataframe containing 20 rows and 3 columns of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame(np.random.randn(20, 3), index=range(0,20), columns=[\"column A\", \"column B\", \"column C\"])\n",
    "print(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the column names using list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# e.g., change to upper case\n",
    "sim_df.columns = [x.upper() for x in sim_df.columns]\n",
    "print(sim_df.head()) #display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., change to last element in string\n",
    "sim_df.columns = [x[-1] for x in sim_df.columns]\n",
    "print(sim_df.tail()) #display last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames\n",
    "\n",
    "We can **concatenate** multiple dataframes containing the same columns (e.g., ['A','B','C']) using [pd.concat()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html). This will stack rows across dataframes.\n",
    "\n",
    "Usage:\n",
    "```\n",
    "pd.concat(\n",
    "    objs,\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    ignore_index=False,\n",
    "    keys=None,\n",
    "    levels=None,\n",
    "    names=None,\n",
    "    verify_integrity=False,\n",
    "    copy=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new dataframes \n",
    "\n",
    "# the first will contain only zeros \n",
    "sim_df1 = pd.DataFrame(np.zeros((3, 3)), index=[20,21,22], columns=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# the second will contain only ones\n",
    "sim_df2 = pd.DataFrame(np.ones((3, 3)), index=[23,24,25], columns=[\"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dfs = [sim_df, sim_df1, sim_df2] # as list of dfs\n",
    "result = pd.concat(sim_dfs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also concatenate using the rows (setting `axis=1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first will contain only zeros \n",
    "sim_df3 = pd.DataFrame(np.zeros((3, 3)), index=[1,2,3], columns=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# the second will contain only ones\n",
    "sim_df4 = pd.DataFrame(np.ones((3, 3)), index=[2,4,5], columns=[\"D\", \"E\", \"F\"])\n",
    "\n",
    "result2 = pd.concat([sim_df3, sim_df4], axis=1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have NaNs (not a number) in cells where there were no data (for example, no data in column `D` for index `1`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be careful because all elements will not merge across rows and columns by default. For example, if the second df also had a column \"C\", we will have two \"C\" columns by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first will contain only zeros \n",
    "sim_df5 = pd.DataFrame(np.zeros((3, 3)), index=[1,2,3], columns=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# the second will contain only ones\n",
    "sim_df6 = pd.DataFrame(np.ones((3, 4)), index=[2,4,5], columns=[\"C\", \"D\", \"E\", \"F\"])\n",
    "\n",
    "result3a = pd.concat([sim_df5, sim_df6], axis=1)\n",
    "print(result3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this method takes the \"union\" of dataframes. This is useful because it means no information will be lost!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, now we have two columns named \"C\". To fix this, we can have pandas rename columns with matching names using the `DataFrame.merge()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3b = sim_df5.merge(sim_df6, how='outer', left_index=True, right_index=True)\n",
    "print(result3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also take the \"intersection\" across the two dataframes. We can do that by setting `join='inner'` (Meaning we only keep the rows that are shared between the two). In the previous case, this would be row '2'. All columns would be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3c = pd.concat([sim_df5, sim_df6], axis=1, join='inner')\n",
    "print(result3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change values within the dataframe using list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's view the column \"subID\"\n",
    "df['subID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's change these value by adding a prefix 'sub_' and store in a new column called \"subID_2\"\n",
    "df['subID_2'] = ['sub_'+str(x) for x in df['subID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subID_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also grab specific elements in the dataframe by specifying rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['age'][df['subID']==1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you know the index (row name), then you can use the `pd.DataFrame.loc` method\n",
    "df.loc[0,'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new columns is particularly useful for computing new variables from old variables. For example: for each subject, let's multiply `age` by `STAB_total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,subject in enumerate(df['subID']):\n",
    "    df.loc[index,'new_col'] = df.loc[index,'age'] * df.loc[index,'STAB_total'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract a column of observations to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = df['subID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sub_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also transpose the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.T.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics with DataFrames\n",
    "\n",
    "We can compute all sorts of descriptive statistics on DataFrame columns using the following methods:\n",
    "- `count()`: Number of non-null observations\n",
    "- `sum()`: Sum of values\n",
    "- `mean()`: Mean of values\n",
    "- `median()`: Median of values\n",
    "- `mode()`: Mode of values\n",
    "- `std()`: Standard deviation of values\n",
    "- `min()`: Minimum value\n",
    "- `max()`: Maximum value\n",
    "- `abs()`: Absolute value\n",
    "- `prod()`: Product of values\n",
    "- `cumsum()`: Cumulative sum\n",
    "- `cumprod()`: Cumulative product\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of a column\n",
    "df[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of multiple columns\n",
    "df[[\"age\",\"STAB_total\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median of a column\n",
    "df[\"age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a summary of metrics on columns\n",
    "df[[\"age\", \"STAB_total\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group means by sex\n",
    "df.groupby(\"sex\")[[\"age\", \"STAB_total\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group means by sex and education\n",
    "df.groupby([\"sex\",\"education_coded\"])[[\"age\", \"STAB_total\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group counts by sex and education\n",
    "df.groupby([\"sex\",\"education_coded\"])[[\"age\", \"STAB_total\"]].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also correlate 2 or more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\",\"STAB_total\",\"socialdistancing\"]].corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data using Matplotlib\n",
    "\n",
    "To understand what our data look like, we will visualize it in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distribiton of one variable in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['age'], bins=9)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of Subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what percentage of subjects have a below-average score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = np.mean(df['age'])\n",
    "frac_below_mean = (df['age'] < mean_age).mean()\n",
    "print(f\"{frac_below_mean:2.1%} of subjects are below the mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see this by adding the average score to the histogram plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['age'], bins=9)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of Subjects\")\n",
    "\n",
    "plt.axvline(mean_age, color=\"orange\", label=\"Mean Age\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_age = np.median(df['age'])\n",
    "\n",
    "plt.hist(df['age'], bins=9)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of Subjects\")\n",
    "\n",
    "plt.axvline(mean_age, color=\"orange\", label=\"Mean Age\")\n",
    "plt.axvline(med_age, color=\"black\", label=\"Median Age\")\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
