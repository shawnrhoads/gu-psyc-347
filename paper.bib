@article{Jolly2017,
author = {Jolly, Eshin and Chang, Luke J.},
doi = {10.1111/tops.12404},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {brain sciences,computational,computational social affective neuroscience,correspondence should be sent,dartmouth,dartmouth college,decision-making,department of psychological and,dual-processing,e-mail,edu,eshin,gr,hanover,jolly,laboratory,nh 03755,psychological education,social,to eshin jolly},
number = {2},
pages = {433--454},
title = {{The flatland fallacy: Moving beyond low dimensional thinking}},
url = {http://doi.wiley.com/10.1111/tops.12404},
volume = {11},
year={2017}
}

@article{Guest2021,
abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
author = {Guest, Olivia and Martin, Andrea E},
journal = {Perspectives on Psychological Science},
keywords = {challenges for scientific inference,cognitive science,computational model,in psychological,open science,path function,pedagogy,philosophy of science,psychology,replicability,reproducibility,research methods,scientific inference,theoretical},
number = {4},
pages = {1--14},
title = {{How Computational Modeling Can Force Theory Building in Psychological Science}},
volume = {16},
year = {2021}
}

@article{Wilson2019,
abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
author = {Wilson, Robert C and Collins, Anne Ge},
doi = {10.7554/eLife.49547},
journal = {eLife},
pages = {e49547},
title = {{Ten simple rules for the computational modeling of behavioral data}},
volume = {8},
year = {2019}
}


@article{Lockwood2020,
abstract = {Social neuroscience aims to describe the neural systems that underpin social cognition and behaviour. Over the past decade, researchers have begun to combine computational models with neuroimaging to link social computations to the brain. Inspired by approaches from reinforcement learning theory, which describes how decisions are driven by the unexpectedness of outcomes, accounts of the neural basis of prosocial learning, observational learning, mentalising and impression formation have been developed. Here we provide an introduction for researchers who wish to use these models in their studies. We consider both theoretical and practical issues related to their implementation, with a focus on specific examples from the field.},
author = {Lockwood, Patricia L. and Klein-Fl{\"{u}}gge, Miriam},
doi = {10.1093/scan/nsaa040},
issn = {1749-5016},
journal = {Social Cognitive and Affective Neuroscience},
number = {8},
pages = {761--771},
title = {{Computational modelling of social cognition and behaviour—a reinforcement learning primer}},
volume = {16},
year = {2020}
}

@article{Zhang2019,
abstract = {The recent years have witnessed a dramatic increase in the use of reinforcement learning (RL) models in social, cognitive and affective neuroscience. This approach, in combination with neuroimaging techniques such as functional magnetic resonance imaging, enables quantitative investigations into latent mechanistic processes. However, increased use of relatively complex computational approaches has led to potential misconceptions and imprecise interpretations. Here, we present a comprehensive framework for the examination of (social) decision-making with the simple Rescorla–Wagner RL model. We discuss common pitfalls in its application and provide practical suggestions. First, with simulation, we unpack the functional role of the learning rate and pinpoint what could easily go wrong when interpreting differences in the learning rate. Then, we discuss the inevitable collinearity between outcome and prediction error in RL models and provide suggestions of how to justify whether the observed neural activation is related to the prediction error rather than outcome valence. Finally, we suggest posterior predictive check is a crucial step after model comparison, and we articulate employing hierarchical modeling for parameter estimation. We aim to provide simple and scalable explanations and practical guidelines for employing RL models to assist both beginners and advanced users in better implementing and interpreting their model-based analyses.},
author = {Zhang, Lei and Lengersdorff, Lukas and Mikus, Nace and Gl{\"{a}}scher, Jan and Lamm, Claus},
journal = {Social Cognitive and Affective Neuroscience},
number = {6},
pages = {695--707},
title = {{Using reinforcement learning models in social neuroscience: Frameworks, pitfalls, and suggestions}},
volume = {15},
doi = {10.1093/scan/nsaa089},
year = {2020}
}

@article{Palminteri2017,
abstract = {In the past decade the field of cognitive sciences has seen an exponential growth in the number of computational modeling studies. Previous work has indicated why and how candidate models of cognition should be compared by trading off their ability to predict the observed data as a function of their complexity. However, the importance of falsifying candidate models in light of the observed data has been largely underestimated, leading to important drawbacks and unjustified conclusions. We argue here that the simulation of candidate models is necessary to falsify models and therefore support the specific claims about cognitive function made by the vast majority of model-based studies. We propose practical guidelines for future research that combine model comparison and falsification.},
author = {Palminteri, Stefano and Wyart, Valentin and Koechlin, Etienne},
doi = {10.1016/j.tics.2017.03.011},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
number = {6},
pages = {425--433},
pmid = {28476348},
title = {{The Importance of Falsification in Computational Cognitive Modeling}},
volume = {21},
year = {2017}
}

@article{Gau2021,
author = {Gau, R. and Noble, S. and Heuer, K. and L., Bottenhorn K. and Bilgin, I. P. and Yang, Y.-F. and Huntenburg, J. M. and Bayer, J. and Bethlehem, R. A. I. and Rhoads, Shawn A. and Vogelbacher, C. and Borghesani, V. and Levitis, E. and Wang, H.-T. and {Van Den Bossche}, S. and Kobeleva, X. and Legarreta, J. H. and Guay, S. and Atay, S. M. and Varoquaux, G. P. and Huijser, D. C. and Sandstr{\"{o}}m, M. S. and Herholz, P. and Nastase, S. A. and Badhwar, A. and Dumas, G. and Schwab, S. and Moia, S. and Dayan, M. and Bassil, Y. and Brooks, P. P. and Mancini, M. and Shine, J. M. and O'Connor, D. and Xie, X. and Poggiali, D. and Friedrich, P. and Heinsfeld, A. S. and Riedl, L. and Toro, R. and Caballero-Gaudes, C. and Eklund, A. and Garner, K. G. and Nolan, C. R. and Demeter, D. V. and Barrios, F. A. and Merchant, J. S. and McDevitt, E. A. and R., Oostenveld and Craddock, R. C. and Rokem, A. and Doyle, A. and Ghosh, S. S. and Nikolaidis, A. and Stanley, O. W. and Uru{\~{n}}uela, E. and {The Brainhack Community}},
doi = {10.1016/j.neuron.2021.04.001},
journal = {Neuron},
pages = {1--16},
title = {{Brainhack: developing a culture of open, inclusive, community-driven neuroscience}},
url = {https://psyarxiv.com/rytjq/},
volume = {109},
year = {2021}
}

@article{VanViegen2021,
abstract = {Neuromatch Academy (NMA) designed and ran a fully online 3-week Computational Neuroscience Summer School for 1757 students with 191 teaching assistants (TAs) working in virtual inverted (or flipped) classrooms and on small group projects. Fourteen languages, active community management, and low cost allowed for an unprecedented level of inclusivity and universal accessibility.},
archivePrefix = {arXiv},
arxivId = {2012.08973},
author = {{van Viegen}, Tara and Akrami, Athena and Bonnen, Kathryn and DeWitt, Eric and Hyafil, Alexandre and Ledmyr, Helena and Lindsay, Grace W. and Mineault, Patrick and Murray, John D. and Pitkow, Xaq and Puce, Aina and Sedigh-Sarvestani, Madineh and Stringer, Carsen and Achakulvisut, Titipat and Alikarami, Elnaz and Atay, Melvin Selim and Batty, Eleanor and Erlich, Jeffrey C. and Galbraith, Byron V. and Guo, Yueqi and Juavinett, Ashley L. and Krause, Matthew R. and Li, Songting and Pachitariu, Marius and Straley, Elizabeth and Valeriani, Davide and Vaughan, Emma and Vaziri-Pashkam, Maryam and Waskom, Michael L. and Blohm, Gunnar and Kording, Konrad and Schrater, Paul and Wyble, Brad and Escola, Sean and Peters, Megan A.K.},
doi = {10.1016/j.tics.2021.03.018},
eprint = {2012.08973},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {Python coding,accessibility,computational neuroscience,data science,education,inclusivity},
number = {7},
pages = {535--538},
pmid = {33994097},
title = {{Neuromatch Academy: Teaching Computational Neuroscience with Global Accessibility}},
volume = {25},
year = {2021}
}

@article{OConnell2021,
abstract = {Antisocial behaviors cause harm, directly or indirectly, to others' welfare. The novel coronavirus pandemic has increased the urgency of understanding a specific form of antisociality: behaviors that increase risk of disease transmission. Because disease transmission-linked behaviors tend to be interpreted and responded to differently than other antisocial behaviors, it is unclear whether general indices of antisociality predict contamination-relevant behaviors. In a preregistered study using an online U.S. sample we found that individuals reporting high levels of antisociality engage in fewer social distancing measures: they report leaving their homes more frequently (p=.016, n=117) and standing closer to others while outside (p{\textless}.001, n=114). These relationships were observed after controlling for sociodemographic variables, illness risk, and use of protective equipment. Antisociality was not significantly associated with level of worry about the coronavirus. These findings suggest that more antisocial individuals may pose health risks to themselves and their community during the COVID-19 pandemic.},
author = {O'Connell, Katherine and Berluti, Kathryn and Rhoads, Shawn and Marsh, Abigail},
doi = {10.1371/journal.pone.0244974},
journal = {PLoS ONE},
keywords = {COVID-19,adult personality,antisocial,social distancing},
number = {1},
pages = {e0244974},
title = {{Reduced social distancing during the COVID-19 pandemic is associated with antisocial behaviors in an online United States sample}},
url = {http://dx.doi.org/10.1371/journal.pone.0244974},
volume = {16},
year = {2021}
}

@article{Scipy,
abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, St{\'{e}}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R.J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^{o}}nio H. and Pedregosa, Fabian and van Mulbregt, Paul and Vijaykumar, Aditya and Bardelli, Alessandro Pietro and Rothberg, Alex and Hilboll, Andreas and Kloeckner, Andreas and Scopatz, Anthony and Lee, Antony and Rokem, Ariel and Woods, C. Nathan and Fulton, Chad and Masson, Charles and H{\"{a}}ggstr{\"{o}}m, Christian and Fitzgerald, Clark and Nicholson, David A. and Hagen, David R. and Pasechnik, Dmitrii V. and Olivetti, Emanuele and Martin, Eric and Wieser, Eric and Silva, Fabrice and Lenders, Felix and Wilhelm, Florian and Young, G. and Price, Gavin A. and Ingold, Gert Ludwig and Allen, Gregory E. and Lee, Gregory R. and Audren, Herv{\'{e}} and Probst, Irvin and Dietrich, J{\"{o}}rg P. and Silterra, Jacob and Webber, James T. and Slavi{\v{c}}, Janko and Nothman, Joel and Buchner, Johannes and Kulick, Johannes and Sch{\"{o}}nberger, Johannes L. and {de Miranda Cardoso}, Jos{\'{e}} Vin{\'{i}}cius and Reimer, Joscha and Harrington, Joseph and Rodr{\'{i}}guez, Juan Luis Cano and Nunez-Iglesias, Juan and Kuczynski, Justin and Tritz, Kevin and Thoma, Martin and Newville, Matthew and K{\"{u}}mmerer, Matthias and Bolingbroke, Maximilian and Tartre, Michael and Pak, Mikhail and Smith, Nathaniel J. and Nowaczyk, Nikolai and Shebanov, Nikolay and Pavlyk, Oleksandr and Brodtkorb, Per A. and Lee, Perry and McGibbon, Robert T. and Feldbauer, Roman and Lewis, Sam and Tygier, Sam and Sievert, Scott and Vigna, Sebastiano and Peterson, Stefan and More, Surhud and Pudlik, Tadeusz and Oshima, Takuya and Pingel, Thomas J. and Robitaille, Thomas P. and Spura, Thomas and Jones, Thouis R. and Cera, Tim and Leslie, Tim and Zito, Tiziano and Krauss, Tom and Upadhyay, Utkarsh and Halchenko, Yaroslav O. and V{\'{a}}zquez-Baeza, Yoshiki},
doi = {10.1038/s41592-019-0686-2},
eprint = {1907.10121},
issn = {15487105},
journal = {Nature Methods},
number = {3},
pages = {261--272},
pmid = {32015543},
title = {{SciPy 1.0: fundamental algorithms for scientific computing in Python}},
volume = {17},
year = {2020}
}

@article{Numpy,
abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
archivePrefix = {arXiv},
arxivId = {2006.10256},
author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'{e}}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'{i}}o, Jaime Fern{\'{a}}ndez and Wiebe, Mark and Peterson, Pearu and G{\'{e}}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
doi = {10.1038/s41586-020-2649-2},
eprint = {2006.10256},
issn = {14764687},
journal = {Nature},
number = {7825},
pages = {357--362},
pmid = {32939066},
publisher = {Springer US},
title = {{Array programming with NumPy}},
url = {http://dx.doi.org/10.1038/s41586-020-2649-2},
volume = {585},
year = {2020}
}

@article{Matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@software{Pandas,
    author = {{The Pandas Development Team}},
    title = {Pandas},
    year = {2020},
    publisher = {Zenodo},
    doi = {10.5281/zenodo.3509134}
}

@article{Lockwood2016,
abstract = {Reinforcement learning theory powerfully characterizes how we learn to benefit ourselves. In this theory, prediction errors—the difference between a predicted and actual outcome of a choice—drive learning. However, we do not operate in a social vacuum. To behave prosocially we must learn the consequences of our actions for other people. Empathy, the ability to vicariously experience and understand the affect of others, is hypothesized to be a critical facilitator of prosocial behaviors, but the link between empathy and prosocial behavior is still unclear. During functional magnetic resonance imaging (fMRI) participants chose between different stimuli that were probabilistically associated with rewards for themselves (self), another person (prosocial), or no one (control). Using computational modeling, we show that people can learn to obtain rewards for others but do so more slowly than when learning to obtain rewards for themselves. fMRI revealed that activity in a posterior portion of the subgenual anterior cingulate cortex/basal forebrain (sgACC) drives learning only when we are acting in a prosocial context and signals a prosocial prediction error conforming to classical principles of reinforcement learning theory. However, there is also substantial variability in the neural and behavioral efficiency of prosocial learning, which is predicted by trait empathy. More empathic people learn more quickly when benefitting others, and their sgACC response is the most selective for prosocial learning. We thus reveal a computational mechanism driving prosocial learning in humans. This framework could provide insights into atypical prosocial behavior in those with disorders of social cognition.},
author = {Lockwood, Patricia L. and Apps, Matthew A. J. and Valton, Vincent and Viding, Essi and Roiser, Jonathan P.},
doi = {10.1073/pnas.1603198113},
isbn = {1603198113},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {35},
pages = {9763--9768},
pmid = {27528669},
title = {{Neurocomputational mechanisms of prosocial learning and links to empathy}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1603198113},
volume = {113},
year = {2016}
}

@article{Peirce2019,
abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and H{\"{o}}chenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindel{\o}v, Jonas Kristoffer},
doi = {10.3758/s13428-018-01193-y},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Experiment,Open science,Open-source,Psychology,Reaction time,Software,Timing},
number = {1},
pages = {195--203},
pmid = {30734206},
publisher = {Behavior Research Methods},
title = {{PsychoPy2: Experiments in behavior made easy}},
volume = {51},
year = {2019}
}

@software{ExecutableBooksCommunity2020,
author = {{Executable Books Community}},
doi = {10.5281/zenodo.2561065},
publisher = {Zenodo},
title = {{Jupyter Book}},
year = {2020}
}

@article{Stanley2013,
abstract = {Nearly 25 years ago, the shared interests of psychologists and biologists in understanding the neural basis of social behavior led to the inception of social neuroscience. In the past decade, this field has exploded, in large part due to the infusion of studies that use fMRI. At the same time, tensions have arisen about how to prioritize a diverse range of questions and about the authority of neurobiological data in answering them. The field is now poised to tackle some of the most interesting and important questions about human and animal behavior but at the same time faces uncertainty about how to achieve focus in its research and cohesion among the scientists who tackle it. The next 25 years offer the opportunity to alleviate some of these growing pains, as well as the challenge of answering large questions that encompass the nature and bounds of diverse social interactions (in humans, including interactions through the internet); how to characterize, and treat, social dysfunction in psychiatric illness; and how to compare social cognition in humans with that in other animals.},
author = {Stanley, Damian A. and Adolphs, Ralph},
doi = {10.1016/j.neuron.2013.10.038},
issn = {08966273},
journal = {Neuron},
number = {3},
pages = {816--826},
pmid = {24183030},
publisher = {Elsevier Inc.},
title = {{Toward a neural basis for social behavior}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.10.038},
volume = {80},
year = {2013}
}

@chapter{Cheong2017,
author = {Cheong, Jin Hyun and Jolly, Eshin and Sul, Sunhae and Chang, Luke J.},
booktitle = {Computational Models of Brain and Behavior},
doi = {10.1002/9781119159193.ch17},
editor = {Moustafa, Ahmed A.},
pages = {229--244},
publisher = {John Wiley {\&} Sons},
title = {{Computational Models in Social Neuroscience}},
year = {2017}
}

@article{Craddock2016,
author = {Craddock, R. Cameron and Margulies, Daniel S. and Bellec, Pierre and Nichols, B. Nolan and Alcauter, Sarael and Barrios, Fernando A. and Burnod, Yves and Cannistraci, Christopher J. and Cohen-Adad, Julien and Leener, Benjamin De and Dery, Sebastien and Downar, Jonathan and Dunlop, Katharine and Franco, Alexandre R. and {Seligman Froehlich}, Caroline and Gerber, Andrew J and Ghosh, Satrajit S. and Grabowski, Thomas J. and Hill, Sean and {S{\'{o}}lon Heinsfeld}, Aniba and Hutchison, R. Matthew and Kundu, Prantik and Laird, Angela R. and Liew, Sook-Lei and Lurie, Daniel J . and McLaren, Donald G. and Meneguzzi, Felipe and Mennes, Maarten and Mesmoudi, Salma and O'Connor, David and Pasaye, Erick H. and Peltier, Scott and Poline, Jean-Baptiste and Prasad, Gautam and {Fraga Pereira}, Ramon and Quirion, Pierre-Olivier and Rokem, Ariel and Saad, Ziad S. and Shi, Yonggang and Strother, Stephen C. and Toro, Roberto and Uddin, Lucina Q. and {Van Horn}, John D. and VanMeter, John W. and Welsh, Robert C. and Xu, Ting},
doi = {10.1186/s13742-016-0121-x},
issn = {2047-217X},
journal = {GigaScience},
keywords = {Collaboration,Data sharing,Hackathon,Networking,Neuroscience,Open science,Unconference,and data,collaboration,data sharing,hackathon,introducing brainhack,networking,neuroscience,open science,open science promotes collaboration,parent dissemination of ideas,through the trans-,tools,unconference,with the},
number = {16},
pages = {1--8},
publisher = {GigaScience},
title = {{Brainhack: A collaborative workshop for the open neuroscience community}},
url = {http://dx.doi.org/10.1186/s13742-016-0121-x},
volume = {5},
year = {2016}
}

@software{Chang2020,
author = {Chang, Luke J. and Huckins, Jeremy and Cheong, Jin Hyun and Brietzke, Sasha and Lindquist, Martin A. and Wager, Tor D.},
doi = {10.5281/zenodo.3909717},
publisher = {Zenodo},
title = {{DartBrains: An online open access resource for learning functional neuroimaging analysis methods in Python.}},
year = {2020}
}
