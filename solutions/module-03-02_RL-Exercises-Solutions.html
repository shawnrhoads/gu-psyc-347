
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>RL Exercises &#8212; Computational Models of Human Social Behavior (and Neuroscience)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://shawnrhoads.github.io/gu-psyc-347/solutions/module-03-02_RL-Exercises-Solutions.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Computational Models of Human Social Behavior (and Neuroscience)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Module 00
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-00_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-01_Course-Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-02_Course-Assignments.html">
   Course Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-03_Reading-List.html">
   Reading List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-04_Getting-Started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-05_Final-Projects.html">
   Final Project Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-00-06_Contributing.html">
   Contributing
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 01
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../module-01-00_Jupyter-Notebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-01-01_Intro-to-Python.html">
   Intro to Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-01-02_Working-with-Data.html">
   Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-01-03_Python-Exercises.html">
   Python Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 02
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../module-02-00_Linear-Modeling.html">
   Linear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-02-01_Nonlinear-Modeling.html">
   Nonlinear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-02-02_Modeling-Exercises.html">
   Modeling Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 03
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../module-03-00_Two-Armed-Bandit.html">
   Two-Armed Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-03-01_Models-of-Learning.html">
   Models of Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-03-02_RL-Exercises.html">
   RL Exercises
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Module 04
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../module-04-00_Social-Learning.html">
   Social Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../module-04-01_Prosocial-RL-Exercises.html">
   Prosocial RL Exercises
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/solutions/module-03-02_RL-Exercises-Solutions.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/shawnrhoads/gu-psyc-347"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/shawnrhoads/gu-psyc-347/issues/new?title=Issue%20on%20page%20%2Fsolutions/module-03-02_RL-Exercises-Solutions.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/shawnrhoads/gu-psyc-347/edit/master/solutions/module-03-02_RL-Exercises-Solutions.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#table-of-contents">
   Table of Contents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#key">
     Key
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#part-1">
   Part 1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-to-know-your-stimuli">
     1. Getting to know your stimuli
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-behavior">
     2. Exploring behavior
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-outcomes">
     3. Exploring outcomes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#part-2">
   Part 2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-a-likelihood-function">
     4. Defining a likelihood function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimizing-the-negative-loglikelihood">
     5. Minimizing the negative loglikelihood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-results-with-your-predictions">
     6. Comparing results with your predictions
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a class="reference external" href="https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-03-02_RL-Exercises.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="rl-exercises">
<h1>RL Exercises<a class="headerlink" href="#rl-exercises" title="Permalink to this headline">¶</a></h1>
<p>These exercises were inspired by and adapted from <a class="reference external" href="http://www.hannekedenouden.ruhosting.nl/RLtutorial/Instructions.html">Models of Learning</a> by Jill O’Reilly and Hanneke den Ouden, <a class="reference external" href="http://u.arizona.edu/~bob/web_NSCS344/index.htm">NSCS 344 - Modeling the Mind</a> by Robert C. Wilson, <a class="reference external" href="https://github.com/shawnrhoads/gu-nsci-526">NSCI 526 - Tutorial 2 (Reinforcement Learning)</a> by Shawn Rhoads, the <a class="reference external" href="https://github.com/cloudssty/Gambling-Game">Gambling Game tutorial</a>, and the <a class="reference external" href="https://github.com/NeuromatchAcademy/course-content">Neuromatch Academy tutorials</a> [<a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p>
<p>In these exercises, we will fit learning behavior to the Rescorla Wagner model of Reinforcement Learning. The data can be downloaded from <a class="reference external" href="https://github.com/shawnrhoads/gu-psyc-347/raw/editing/docs/static/data/RL-Exercises-Data.zip">GitHub</a>, Canvas, or by using the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">requests</span>

<span class="c1"># create list of URLs</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;https://raw.githubusercontent.com/shawnrhoads/gu-psyc-347/master/docs/static/data/sub-</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">_RLdata.csv&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">)]</span>

<span class="c1"># loop through list and download data</span>
<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s1">&#39;../static/data&#39;</span><span class="p">):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;static/data/&#39;</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_4061</span><span class="o">/</span><span class="mf">2567928728.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>         <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">13</span>     <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;static/data/sub-00_RLdata.csv&#39;
</pre></div>
</div>
</div>
</div>
<p>Now, that we’ve downloaded our data, let’s explore it together!</p>
<div class="section" id="table-of-contents">
<h2>Table of Contents<a class="headerlink" href="#table-of-contents" title="Permalink to this headline">¶</a></h2>
<p><strong>Part 1</strong></p>
<ol class="simple">
<li><p><a class="reference external" href="#1.-Getting-to-know-your-stimuli">Getting to know your stimuli</a></p></li>
<li><p><a class="reference external" href="#2.-Exploring-behavior">Exploring behavior</a></p></li>
<li><p><a class="reference external" href="#3.-Exploring-outcomes">Exploring outcomes</a></p></li>
</ol>
<p><strong>Part 2</strong>
4. <span class="xref myst">Defining a likelihood function</span>
5. <span class="xref myst">Minimizing the negative loglikelihood</span>
6. <span class="xref myst">Comparing results with your predictions</span></p>
<div class="section" id="key">
<h3>Key<a class="headerlink" href="#key" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">[INSERT</span> <span class="pre">CODE</span> <span class="pre">BELOW]</span></code> : indicates where you should insert your own code, feel free to replace with a comment of your own</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">...</span></code>: indicates a location where you should insert your own code</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span> <span class="pre">NotImplementedError(&quot;Student</span> <span class="pre">exercise:</span> <span class="pre">*&quot;)</span></code> : delete this line once you have added your code</p></li>
</ul>
<hr></div>
</div>
<div class="section" id="part-1">
<h2>Part 1<a class="headerlink" href="#part-1" title="Permalink to this headline">¶</a></h2>
<p>You will break out in groups of 2-3 to discuss the following questions (<font color='red'>highlighted in red font</font>) and implement code to answer them. I have prepared a few functions that will help you along the way.</p>
<p>Then, we will re-group with the entire class to discuss what we’ve learned. Please remember to save your work. This will count towards your Jupyter Notebook Exercise #3 grade.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first let&#39;s import our packages</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span> <span class="c1"># finding optimal params in models</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>             <span class="c1"># statistical tools</span>
<span class="kn">import</span> <span class="nn">os</span>                           <span class="c1"># operating system tools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                  <span class="c1"># matrix/array functions</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                 <span class="c1"># loading and manipulating data</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>        <span class="c1"># interactive display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>     <span class="c1"># plotting</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>                <span class="c1"># set seed for reproducibility</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this function will load the data into memory (assuming that</span>
<span class="c1"># the data are downloaded)</span>
<span class="k">def</span> <span class="nf">load_subjects</span><span class="p">(</span><span class="n">how_many</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    input: number of subjects&#39; data to load from 1-14</span>
<span class="sd">    output: dictionary of DataFrames containing the data</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">assert</span> <span class="p">(</span><span class="n">how_many</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">how_many</span> <span class="o">&lt;=</span> <span class="mi">15</span><span class="p">),</span> <span class="s2">&quot;0 &lt; how_many &lt; 15&quot;</span>
    
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s1">&#39;../static/data&#39;</span><span class="p">):</span>
        <span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;../static/data/sub-</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">_RLdata.csv&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">how_many</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;sub-</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">_RLdata.csv&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">how_many</span><span class="p">)]</span>
    
    <span class="n">subject_data</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">files</span><span class="p">):</span>
        <span class="n">subject_data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">subject_data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s load in our data using the function above</span>
<span class="c1"># feel free to adjust `how_many` (the default is all 15 subjects)</span>
<span class="n">subject_data</span> <span class="o">=</span> <span class="n">load_subjects</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="getting-to-know-your-stimuli">
<h3>1. Getting to know your stimuli<a class="headerlink" href="#getting-to-know-your-stimuli" title="Permalink to this headline">¶</a></h3>
<p>Subjects played a few rounds of the two-armed bandit task, in which they learned the reward probability distribution of two slot machines (<strong>stim_A</strong> and <strong>stim_B</strong>) through trial-and-error.</p>
<p><font color="red">1a. How many trials did each subject complete?</font> (<em>Hint: explore the Dictionary of DataFrames</em>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">subject_behavior</span> <span class="ow">in</span> <span class="n">subject_data</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subject_behavior</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; trials, &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 50 trials, 
</pre></div>
</div>
</div>
</div>
<p><strong>ANSWER 1a:</strong></p>
<p>Each subject completed 50 trials corresponding to 50 rows in each DataFrame.</p>
<p>Each slot machine was associated with a different mean probability (i.e., <strong>stim_A</strong> yielded rewards according to a constant probability and <strong>stim_B</strong> yielded rewards according to a different constant probability).</p>
<p><font color="red">1b. What were the probabilities of each stimulus?<br>
1c. Did <strong>stim_A</strong> have the same probability for every subject? <strong>stim_B</strong>? Why or why not?</font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">subject_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span> <span class="c1"># first subject head</span>
<span class="n">display</span><span class="p">(</span><span class="n">subject_data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span> <span class="c1"># third subject head</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stim_A</th>
      <th>stim_B</th>
      <th>choice</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.2</td>
      <td>0.8</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stim_A</th>
      <th>stim_B</th>
      <th>choice</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.8</td>
      <td>0.2</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>ANSWER 1b:</strong></p>
<p>Each stimulus yielded rewards with either a 20% or 80% chance.</p>
<p><strong>ANSWER 1c:</strong></p>
<p>The stimuli displayed to subject #1 have different probabilities than the stimuli displayed to subject #3. The probabilities of yielding rewarding outcomes are randomly assigned to each stimulus for each subject because we don’t want learning to be confounded with the <em><strong>stimuli</strong></em>. For example, that means we don’t want it to be the case that learning for a red stimulus is easiest across subjects and thus confounded stimulus type would be confounded with learning (see lecture from 3/2/2021).</p>
</div>
<div class="section" id="exploring-behavior">
<h3>2. Exploring behavior<a class="headerlink" href="#exploring-behavior" title="Permalink to this headline">¶</a></h3>
<p>People learn (or don’t) in many different ways. Some people are extremely sensitive when outcomes aren’t what they expected. Others aren’t willing to update their behaviors so quickly.</p>
<p>People also make decisions differently. Some people are more explorative and are event willing to try a riskier action just to see what happens. Others are more “deterministic” with their actions tend to stick with what they know is best.</p>
<p>While there are plenty more ways people vary in their learning and decision-making behavior, we are going to explore these two aspects.</p>
<p><em>Hint: please use the <code class="docutils literal notranslate"><span class="pre">plot_behavior()</span></code> function to explore different aspects of subjects’ behavior and outcomes</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_behavior</span><span class="p">(</span><span class="n">subject_data</span><span class="p">,</span> <span class="n">subject_id</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">outcomes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    input: </span>
<span class="sd">        subject_data: dictionary containing</span>
<span class="sd">        subject_id: integer from 0-14 corresponding to an ID number</span>
<span class="sd">        choices: boolean indicating whether to plot choices or not</span>
<span class="sd">        outcomes: boolean indicating whether to plot outcomes or not</span>
<span class="sd">        probability: boolean indicating whether to plot the mean reward over trials for both stimuli or not</span>
<span class="sd">    output:</span>
<span class="sd">        plot of behavior</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">subject_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">,</span> <span class="s2">&quot;`subject_data` should be a dictionary, run the `load_subjects()` function above to load the data into memory&quot;</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">subject_id</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span> <span class="ow">and</span> <span class="n">subject_id</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">subject_id</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">,</span> <span class="s2">&quot;`subject_id` should be an integer between 0 and 14&quot;</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">subject_data</span><span class="p">[</span><span class="n">subject_id</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">probability</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">choice</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">outcome</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">choice</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">outcome</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;purple&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
    <span class="k">if</span> <span class="n">outcomes</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)),</span> <span class="n">data</span><span class="o">.</span><span class="n">outcome</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">choices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">choice</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">.5</span><span class="p">:</span>
            <span class="n">choice_data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">choice</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">choice_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">choice</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)),</span> <span class="n">choice_data</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Behavior from subject #</span><span class="si">{</span><span class="n">subject_id</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Plot everyone’s behavior and answer the following questions (<em>pro-tip: there’s way to plot everyone’s data using only two lines of code; can you figure it out?</em>).
<br><br></p>
<font color="red">
    2a. Which subjects were most sensitive to previous unexpected outcomes? In other words, who changed their decisions most often after a prediction error? List the subject ID numbers. Describe which aspect(s) of the data led you to this conclusion. What parameter from the Rescorla-Wagner Model captures this tendency?<br>
    2b. Which subjects were least explorative in their behavior? List the subject ID numbers. Describe which aspect(s) of the data led you to this conclusion. What parameter from the Rescorla-Wagner Model captures this tendency?</font><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># one subject</span>
<span class="n">plot_behavior</span><span class="p">(</span><span class="n">subject_data</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outcomes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/module-03-02_RL-Exercises-Solutions_19_0.png" src="../_images/module-03-02_RL-Exercises-Solutions_19_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># all subjects</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">plot_behavior</span><span class="p">(</span><span class="n">subject_data</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">outcomes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># all subjects using in one line of code [plot_behavior(subject_data, x, choices=True, outcomes=True, probability=True) for x in range(15)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_0.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_0.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_1.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_1.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_2.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_2.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_3.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_3.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_4.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_4.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_5.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_5.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_6.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_6.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_7.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_7.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_8.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_8.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_9.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_9.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_10.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_10.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_11.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_11.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_12.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_12.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_13.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_13.png" />
<img alt="../_images/module-03-02_RL-Exercises-Solutions_20_14.png" src="../_images/module-03-02_RL-Exercises-Solutions_20_14.png" />
</div>
</div>
<p><strong>ANSWER 2a:</strong></p>
<p>Subjects that changed their choices most often after they (1) selected the stimulus with the highest probability of yielding reward but did not receive a rewarding outcome or (2) selected the stimulus with the lowest probability of yielding reward, but did in-fact receive a rewarding outcome. For example, see  plots for subjects 4, 10, 12, and 14.</p>
<p><strong>ANSWER 2b:</strong></p>
<p>Subejcts that were less explorative were those who were less likely to select the stimulus with the lowest probability of yielding reward after they learned the association. They were people who selected stimuli more randomly during early trials, but eventually almost always selected the better option. For example, see  plots for subjects 1, 3, 7, 9, and 13.</p>
</div>
<div class="section" id="exploring-outcomes">
<h3>3. Exploring outcomes<a class="headerlink" href="#exploring-outcomes" title="Permalink to this headline">¶</a></h3>
<p><font color="red">Earlier, we learned that the reward probabilities of each stimulus were fixed, how do these values compare with the actual mean reward over trials across subjects (according to their choices)? Are they similar? Why or why not?</font> (<em>Hint: see plots above and/or explore different subjects’ “outcome” column</em>)<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">s</span><span class="o">.</span><span class="n">stim_A</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">.5</span><span class="p">:</span> <span class="c1"># only print high probability stimulus</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;probability that stim A yielded reward: </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">stim_A</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;actual frequency of choosing stim A: </span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="o">.</span><span class="n">choice</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;actual mean reward: </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">outcome</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;probability that stim B yielded reward: </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">stim_B</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;actual frequency of choosing stim B: </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">choice</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;actual mean reward: </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">outcome</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 0
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.60
actual mean reward: 0.52

subject 1
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.70
actual mean reward: 0.62

subject 2
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.68
actual mean reward: 0.58

subject 3
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.86
actual mean reward: 0.70

subject 4
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.54
actual mean reward: 0.54

subject 5
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.74
actual mean reward: 0.50

subject 6
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.66
actual mean reward: 0.68

subject 7
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.88
actual mean reward: 0.68

subject 8
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.88
actual mean reward: 0.70

subject 9
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.90
actual mean reward: 0.74

subject 10
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.80
actual mean reward: 0.74

subject 11
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.88
actual mean reward: 0.66

subject 12
probability that stim B yielded reward: 0.80
actual frequency of choosing stim B: 0.68
actual mean reward: 0.54

subject 13
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.86
actual mean reward: 0.76

subject 14
probability that stim A yielded reward: 0.80
actual frequency of choosing stim A: 0.60
actual mean reward: 0.56
</pre></div>
</div>
</div>
</div>
<p><strong>ANSWER 3:</strong></p>
<p>The mean values of the actual outcomes/rewards are more similar to the actual probabilities when people learned the associative values (i.e., they are closer to .80), but deviated when people did not learn to choose the stimuli with the higher reward probability as well. Participants learned if the frequency of choosing the stimulus that yielded the higher reward was &gt;50%. See above.</p>
<p>Great job! Don’t forget to save any of your work. It will also be useful for <strong>Part 2</strong>!</p>
<hr></div>
</div>
<div class="section" id="part-2">
<h2>Part 2<a class="headerlink" href="#part-2" title="Permalink to this headline">¶</a></h2>
<p>Now that we have explored the data and gotten a sense about participants’ behaviors during the task, let’s estimate models that explain their learning!</p>
<p>We will:</p>
<ul class="simple">
<li><p>Define a function that computes the negative loglikelihood given the data and Rescorla-Wagner Model</p></li>
<li><p>Implement an minimization algorithm that loops through possible combinations of <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> for each subject in order to find the parameters that minimize the negative loglikelihood. Each subject (<span class="math notranslate nohighlight">\(i\)</span>) will have a separate set of parameters <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(\theta_i\)</span>, which respectively correspond to the learning rate and inverse temperature</p></li>
<li><p>Compare the estimated parameter values for <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(\theta_i\)</span> to your initial predictions in Questions <a class="reference external" href="#2.-Exploring-behavior">#2a-b</a>.</p></li>
</ul>
<div class="section" id="defining-a-likelihood-function">
<h3>4. Defining a likelihood function<a class="headerlink" href="#defining-a-likelihood-function" title="Permalink to this headline">¶</a></h3>
<p>Recall that our goal is to find the parameter values of a model that maximize the likelihood of the data. In the Rescorla-Wagner case, we want to maximize the likelihood (a.k.a. minimize the loglikelihood) of the data given parameter values (<span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>) of the model.</p>
<p>In the Rescorla-Wagner Model, the likelihood of the data are given by the probability of making a choice on a give trial, <span class="math notranslate nohighlight">\(p(c_t)\)</span>.</p>
<p>That is, participants use the stimuli values to guide their decisions, choosing the most valuable option most frequently, but occasionally making ‘mistakes’ (or exploring) by choosing a low value option. One choice rule with these properties is known as the <strong>‘softmax’ choice rule</strong>, which chooses option <span class="math notranslate nohighlight">\(k\)</span> with probability:</p>
<div class="math notranslate nohighlight">
\[
p^k_t = \frac{\exp(\theta Q^k_t)}{\sum_{i=1}^K \exp(\theta Q^i_t)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> is the ‘inverse temperature’ parameter that controls the level of stochasticity in the choice, ranging from <span class="math notranslate nohighlight">\(\theta = 0\)</span> for completely random responding and <span class="math notranslate nohighlight">\(\theta = \infty\)</span> for deterministically choosing the highest value option.</p>
<p>The value of each stimulus <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(Q^k_t\)</span> is updated in response to reward <span class="math notranslate nohighlight">\(r_t\)</span> according to:</p>
<div class="math notranslate nohighlight">
\[
Q^k_{t+1} = Q^k_t + \alpha (r_t - Q^k_t)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate, which is bounded between 0 and 1 and captures the extent to which the prediction error, <span class="math notranslate nohighlight">\((r_t - Q^k_t)\)</span>, updates the value (i.e., a higher <span class="math notranslate nohighlight">\(\alpha\)</span> value will put greater weight on the prediction error). For simplicity, we assume that the initial value, <span class="math notranslate nohighlight">\(Q^k_0=0\)</span>, although it is possible to treat the <span class="math notranslate nohighlight">\(Q^k_0\)</span> as a free parameter of the model (this is also the intercept).</p>
<p>Combining the learning and decision rules gives a simple model of decision making in this task with two free parameters: the learning rate, <span class="math notranslate nohighlight">\(\alpha\)</span>, and the inverse temperature <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Thus, for any given (<span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>) of the model, the negative loglikelihood <span class="math notranslate nohighlight">\(negative \log \mathcal{L}\)</span> will be computed as:</p>
<div class="math notranslate nohighlight">
\[
negative \log \mathcal{L} = -\sum_{t=1}^T \log p(c_t)
\]</div>
<p>Below we will define a function that computes the negative loglikelihood given the data and Rescorla-Wagner Model (see <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-01-01_Intro-to-Python.html">Intro to Python</a> for functions, <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-02-02_Modeling-Exercises.html">Modeling Exercises</a> and <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html">Models of Learning</a> for negative loglikelihood, and <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html">Models of Learning</a> for the Rescorla-Wagner Model).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fill in the `...` below to estimate model params for each subject</span>

<span class="k">def</span> <span class="nf">negll_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">choices</span><span class="p">,</span> <span class="n">outcomes</span><span class="p">):</span>

    <span class="c1"># [INSERT CODE BELOW]</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: complete the code below to define that computes the negative loglikelihood for the Rescorla-Wagner Model of Learning, then delete this line&quot;</span><span class="p">)</span>

    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span> 
    
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span> <span class="c1"># check inputs</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">choices</span><span class="p">,</span> <span class="n">outcomes</span> 

        <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> 
        <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span> <span class="c1"># Q at trial 0</span>
        <span class="n">Q_stored</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span> 
        <span class="n">choiceProb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span> 

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span> <span class="c1"># add comment</span>

            <span class="c1"># compute choice probabilities for k=2</span>
            <span class="c1"># use the softmax rule</span>
            <span class="n">ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Q</span><span class="p">))</span>
            <span class="n">sum_ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">ev</span> <span class="o">/</span> <span class="n">sum_ev</span>

            <span class="c1"># compute choice probability for actual choice</span>
            <span class="n">choiceProb</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> 

            <span class="c1"># update values</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
            <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="o">...</span>

            <span class="c1"># store Q_t+1</span>
            <span class="n">Q_stored</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span>

        <span class="n">negLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">choiceProb</span><span class="p">))</span> 
    
        <span class="k">return</span> <span class="n">negLL</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># solution</span>

<span class="k">def</span> <span class="nf">negll_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">choices</span><span class="p">,</span> <span class="n">outcomes</span><span class="p">):</span>
    
    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span> 
    
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span> <span class="c1"># check inputs</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">choices</span><span class="p">,</span> <span class="n">outcomes</span> 

        <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> 
        <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span> <span class="c1"># Q at trial 0</span>
        <span class="n">Q_stored</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span> 
        <span class="n">choiceProb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span> 

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span> <span class="c1"># add comment</span>

            <span class="c1"># compute choice probabilities for k=2</span>
            <span class="c1"># use the softmax rule</span>
            <span class="n">ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Q</span><span class="p">))</span>
            <span class="n">sum_ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">ev</span> <span class="o">/</span> <span class="n">sum_ev</span>

            <span class="c1"># compute choice probability for actual choice</span>
            <span class="n">choiceProb</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> 
            
            <span class="c1"># update values</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
            <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>

            <span class="c1"># store Q_t+1</span>
            <span class="n">Q_stored</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span>

        <span class="n">negLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">choiceProb</span><span class="p">))</span> <span class="c1"># add comment</span>
    
        <span class="k">return</span> <span class="n">negLL</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s develop an intuition for how this function works. Make a guess for subejct #3’s <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> to compute the negative loglikelihood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fill in the `...` below to make guess for alpha and theta for subject #3</span>
<span class="c1"># then, fill in the inputs for the function</span>

<span class="c1"># [INSERT CODE BELOW]</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: make guess for alpha and theta to compute the negative loglikelihood, then delete this line&quot;</span><span class="p">)</span>

<span class="n">alpha_guess</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">#number between 0-1</span>
<span class="n">theta_guess</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">#number between 1-8</span>
<span class="n">subj3_choices</span> <span class="o">=</span> <span class="n">subject_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">choice</span>
<span class="n">subj3_outcomes</span> <span class="o">=</span> <span class="n">subject_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">outcomes</span>

<span class="c1"># compute the negative ll</span>
<span class="n">subj3_negll</span> <span class="o">=</span> <span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">subj3_choices</span><span class="p">,</span> <span class="n">subj3_outcomes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;given alpha=</span><span class="si">{</span><span class="n">alpha_guess</span><span class="si">}</span><span class="s1"> and theta=</span><span class="si">{</span><span class="n">theta_guess</span><span class="si">}</span><span class="s1">, the negative loglikelihood is </span><span class="si">{</span><span class="n">subj3_negll</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NotImplementedError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_4061</span><span class="o">/</span><span class="mf">1250918315.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># [INSERT CODE BELOW]</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: make guess for alpha and theta to compute the negative loglikelihood, then delete this line&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> 
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">alpha_guess</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">#number between 0-1</span>

<span class="ne">NotImplementedError</span>: Student exercise: make guess for alpha and theta to compute the negative loglikelihood, then delete this line
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># solution</span>

<span class="n">alpha_guess</span> <span class="o">=</span> <span class="mf">.1</span>
<span class="n">theta_guess</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">subj3_choices</span> <span class="o">=</span> <span class="n">subject_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">choice</span>
<span class="n">subj3_outcomes</span> <span class="o">=</span> <span class="n">subject_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">outcome</span>

<span class="c1"># compute the negative ll</span>
<span class="n">subj3_negll</span> <span class="o">=</span> <span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_guess</span><span class="p">,</span> <span class="n">theta_guess</span><span class="p">],</span> <span class="n">subj3_choices</span><span class="p">,</span> <span class="n">subj3_outcomes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;given alpha=</span><span class="si">{</span><span class="n">alpha_guess</span><span class="si">}</span><span class="s1"> and theta=</span><span class="si">{</span><span class="n">theta_guess</span><span class="si">}</span><span class="s1">, the negative loglikelihood is </span><span class="si">{</span><span class="n">subj3_negll</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>given alpha=0.1 and theta=1.5, the negative loglikelihood is 25.91
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="minimizing-the-negative-loglikelihood">
<h3>5. Minimizing the negative loglikelihood<a class="headerlink" href="#minimizing-the-negative-loglikelihood" title="Permalink to this headline">¶</a></h3>
<p>Now that we have a function, implement an minimization algorithm that loops through possible combinations of <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> for each subject in order to find the parameters that minimize the negative loglikelihood. Each subject (<span class="math notranslate nohighlight">\(i\)</span>) will have a separate set of parameters <span class="math notranslate nohighlight">\(\alpha_i\)</span> and <span class="math notranslate nohighlight">\(\theta_i\)</span>, which respectively correspond to the learning rate and inverse temperature (see <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html">Models of Learning</a>.</p>
<p>Importantly, we will store these parameters in a Pandas DataFrame with 15 rows corresponding to subjects, and 2 columns corresponding to <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> (see <a class="reference external" href="https://shawnrhoads.github.io/gu-psyc-347/module-01-02_Working-with-Data.html">Working with Data</a> for more on Pandas DataFrames).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fill in the `...` below to estimate model params for each subject</span>

<span class="c1"># [INSERT CODE BELOW]</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: complete the code below to estimate model parameters for each subject, then delete this line&quot;</span><span class="p">)</span>

<span class="c1">#initialize dataframe to store results</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">subject_data</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">])</span>

<span class="c1"># loop through subjects</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">behavior</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="o">...</span><span class="p">,</span> <span class="o">...</span> <span class="o">=</span> <span class="n">behavior</span><span class="o">.</span><span class="n">choice</span><span class="p">,</span> <span class="n">behavior</span><span class="o">.</span><span class="n">outcome</span>
    
    <span class="c1"># gradient descent to minimize neg LL</span>
    <span class="n">res_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># set initial neg LL to be inf</span>

    <span class="c1"># guess several different starting points for alpha</span>
    <span class="k">for</span> <span class="n">alpha_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">12</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">theta_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">):</span>

            <span class="c1"># guesses for alpha, theta will change on each loop</span>
            <span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>

            <span class="c1"># minimize neg LL</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> 
                              <span class="o">...</span><span class="p">,</span> 
                              <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span> 
                              <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)))</span>

            <span class="c1"># if current negLL is smaller than the last negLL,</span>
            <span class="c1"># then store current data</span>
            <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="n">res_nll</span><span class="p">:</span>
                <span class="n">res_nll</span> <span class="o">=</span> <span class="o">...</span>
                <span class="n">param_fits</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># also, compute BIC</span>
    <span class="n">BIC</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_guess</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">res_nll</span>
    
    <span class="c1">#store in dataframe</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">index</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">: $\alpha$=</span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, $\theta$=</span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">; negLL=</span><span class="si">{</span><span class="n">res_nll</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">; BIC=</span><span class="si">{</span><span class="n">BIC</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">  File</span><span class="nn"> &quot;/tmp/ipykernel_4061/3296750088.py&quot;</span><span class="gt">, line </span><span class="mi">11</span>
    <span class="o">...</span><span class="p">,</span> <span class="o">...</span> <span class="o">=</span> <span class="n">behavior</span><span class="o">.</span><span class="n">choice</span><span class="p">,</span> <span class="n">behavior</span><span class="o">.</span><span class="n">outcome</span>
    <span class="o">^</span>
<span class="ne">SyntaxError</span>: can&#39;t assign to Ellipsis
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># solution</span>

<span class="c1">#initialize dataframe</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">subject_data</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">])</span>
<span class="c1"># loop through subjects</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">behavior</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subject_data</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">behavior</span><span class="o">.</span><span class="n">choice</span><span class="p">,</span> <span class="n">behavior</span><span class="o">.</span><span class="n">outcome</span>
    
    <span class="c1"># gradient descent to minimize neg LL</span>
    <span class="n">res_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># set initial neg LL to be inf</span>

    <span class="c1"># guess several different starting points for alpha</span>
    <span class="k">for</span> <span class="n">alpha_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">theta_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>

            <span class="c1"># guesses for alpha, theta will change on each loop</span>
            <span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_guess</span><span class="p">,</span> <span class="n">theta_guess</span><span class="p">)</span>

            <span class="c1"># minimize neg LL</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">negll_RescorlaWagner</span><span class="p">,</span> 
                              <span class="n">init_guess</span><span class="p">,</span> 
                              <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span> 
                              <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)))</span>

            <span class="c1"># if current negLL is smaller than the last negLL,</span>
            <span class="c1"># then store current data</span>
            <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="n">res_nll</span><span class="p">:</span>
                <span class="n">res_nll</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
                <span class="n">param_fits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

    <span class="c1"># also, compute BIC</span>
    <span class="n">BIC</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_guess</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">res_nll</span>
    
    <span class="c1">#store in dataframe</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;subject </span><span class="si">{</span><span class="n">index</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1">: alpha=</span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, theta=</span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">; negLL=</span><span class="si">{</span><span class="n">res_nll</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">; BIC=</span><span class="si">{</span><span class="n">BIC</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 00: alpha=0.47, theta=0.74; negLL=33.17; BIC=74.16
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 01: alpha=0.06, theta=3.77; negLL=26.89; BIC=61.61
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 02: alpha=0.31, theta=1.55; negLL=32.05; BIC=71.92
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 03: alpha=0.16, theta=5.41; negLL=16.37; BIC=40.57
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 04: alpha=0.79, theta=0.64; negLL=33.92; BIC=75.67
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 05: alpha=0.38, theta=3.38; negLL=25.08; BIC=57.98
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 06: alpha=0.07, theta=1.66; negLL=32.01; BIC=71.84
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 07: alpha=0.18, theta=6.61; negLL=14.13; BIC=36.08
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subject 08: alpha=0.44, theta=3.33; negLL=16.04; BIC=39.90
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_4061</span><span class="o">/</span><span class="mf">844010008.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>                               <span class="n">init_guess</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>                               <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span>
<span class="ne">---&gt; </span><span class="mi">23</span>                               <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">)))</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> 
<span class="g g-Whitespace">     </span><span class="mi">25</span>             <span class="c1"># if current negLL is smaller than the last negLL,</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_minimize.py</span> in <span class="ni">minimize</span><span class="nt">(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)</span>
<span class="g g-Whitespace">    </span><span class="mi">622</span>     <span class="k">elif</span> <span class="n">meth</span> <span class="o">==</span> <span class="s1">&#39;l-bfgs-b&#39;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">623</span>         <span class="k">return</span> <span class="n">_minimize_lbfgsb</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">624</span>                                 <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">625</span>     <span class="k">elif</span> <span class="n">meth</span> <span class="o">==</span> <span class="s1">&#39;tnc&#39;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">626</span>         <span class="k">return</span> <span class="n">_minimize_tnc</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">,</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py</span> in <span class="ni">_minimize_lbfgsb</span><span class="nt">(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">358</span>             <span class="c1"># until the completion of the current minimization iteration.</span>
<span class="g g-Whitespace">    </span><span class="mi">359</span>             <span class="c1"># Overwrite f and g:</span>
<span class="ne">--&gt; </span><span class="mi">360</span>             <span class="n">f</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">func_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">361</span>         <span class="k">elif</span> <span class="n">task_str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="sa">b</span><span class="s1">&#39;NEW_X&#39;</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">362</span>             <span class="c1"># new iteration</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py</span> in <span class="ni">fun_and_grad</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">    </span><span class="mi">266</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_update_x_impl</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_update_fun</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">268</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_update_grad</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">269</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">g</span>
<span class="g g-Whitespace">    </span><span class="mi">270</span> 

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py</span> in <span class="ni">_update_grad</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span>     <span class="k">def</span> <span class="nf">_update_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">237</span>         <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_updated</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">238</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_update_grad_impl</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">239</span>             <span class="bp">self</span><span class="o">.</span><span class="n">g_updated</span> <span class="o">=</span> <span class="kc">True</span>
<span class="g g-Whitespace">    </span><span class="mi">240</span> 

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py</span> in <span class="ni">update_grad</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">154</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">ngev</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="n">approx_derivative</span><span class="p">(</span><span class="n">fun_wrapped</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">f0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">156</span>                                            <span class="o">**</span><span class="n">finite_diff_options</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span> 
<span class="g g-Whitespace">    </span><span class="mi">158</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_update_grad_impl</span> <span class="o">=</span> <span class="n">update_grad</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_numdiff.py</span> in <span class="ni">approx_derivative</span><span class="nt">(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span>         <span class="k">if</span> <span class="n">sparsity</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>             <span class="k">return</span> <span class="n">_dense_difference</span><span class="p">(</span><span class="n">fun_wrapped</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">487</span>                                      <span class="n">use_one_sided</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">488</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">489</span>             <span class="k">if</span> <span class="ow">not</span> <span class="n">issparse</span><span class="p">(</span><span class="n">sparsity</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">sparsity</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_numdiff.py</span> in <span class="ni">_dense_difference</span><span class="nt">(fun, x0, f0, h, use_one_sided, method)</span>
<span class="g g-Whitespace">    </span><span class="mi">555</span>             <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">h_vecs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">556</span>             <span class="n">dx</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># Recompute dx as exactly representable number.</span>
<span class="ne">--&gt; </span><span class="mi">557</span>             <span class="n">df</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">f0</span>
<span class="g g-Whitespace">    </span><span class="mi">558</span>         <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;3-point&#39;</span> <span class="ow">and</span> <span class="n">use_one_sided</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
<span class="g g-Whitespace">    </span><span class="mi">559</span>             <span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">h_vecs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_numdiff.py</span> in <span class="ni">fun_wrapped</span><span class="nt">(x)</span>
<span class="g g-Whitespace">    </span><span class="mi">435</span> 
<span class="g g-Whitespace">    </span><span class="mi">436</span>     <span class="k">def</span> <span class="nf">fun_wrapped</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">437</span>         <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">438</span>         <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">439</span>             <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;`fun` return value has &quot;</span>

<span class="nn">/usr/share/miniconda3/envs/gu-psyc-347-jb/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py</span> in <span class="ni">fun_wrapped</span><span class="nt">(x)</span>
<span class="g g-Whitespace">    </span><span class="mi">132</span>             <span class="c1"># Overwriting results in undefined behaviour because</span>
<span class="g g-Whitespace">    </span><span class="mi">133</span>             <span class="c1"># fun(self.x) will change self.x, with the two no longer linked.</span>
<span class="ne">--&gt; </span><span class="mi">134</span>             <span class="k">return</span> <span class="n">fun</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">135</span> 
<span class="g g-Whitespace">    </span><span class="mi">136</span>         <span class="k">def</span> <span class="nf">update_fun</span><span class="p">():</span>

<span class="nn">/tmp/ipykernel_4061/1053038448.py</span> in <span class="ni">negll_RescorlaWagner</span><span class="nt">(params, choices, outcomes)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>             <span class="n">ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Q</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>             <span class="n">sum_ev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">24</span>             <span class="n">p</span> <span class="o">=</span> <span class="n">ev</span> <span class="o">/</span> <span class="n">sum_ev</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> 
<span class="g g-Whitespace">     </span><span class="mi">26</span>             <span class="c1"># compute choice probability for actual choice</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="comparing-results-with-your-predictions">
<h3>6. Comparing results with your predictions<a class="headerlink" href="#comparing-results-with-your-predictions" title="Permalink to this headline">¶</a></h3>
<p>How were your predictions? <font color="red">Do these parameters somewhat map onto what you expected solely based on their behavior?</font> It’s okay if they didn’t!</p>
<p><strong>ANSWER 6:</strong></p>
<p>Depends on students’ answers to question 2a and 2b above.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./solutions"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Shawn A. Rhoads<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KG3N20S55G"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('config', 'G-KG3N20S55G');
                </script>

  </body>
</html>